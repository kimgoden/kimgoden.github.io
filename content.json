{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/11/02/hello-world/"},{"title":"Pandas 기초 사용법","text":"Pandas 사용123import pandas as pdprint(pd.__version__)# pandas 사용환경 설정 1.1.5 1import numpy as np 테스트12df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})print(type(df)) &lt;class 'pandas.core.frame.DataFrame'&gt; 구글 드라이브와 연동123from google.colab import drivedrive.mount('/content/drive')# 구글 드라이브와 colab을 연동하여 드라이브의 파일을 가져올 수 있다. Mounted at /content/drive 123456789101112131415DATA_PATH = &quot;경로를 입력하시기를 바랍니다.&quot;DATA_PATH = '/content/drive/MyDrive/lectures_210923/PART_I_Intro/'&quot;&quot;&quot; 파일을 불러올 때는 경로를 잘 확인하여야 한다. 이 형식처럼 경로를 나눠저 적어도 되지만 DATA_PATH = '/content/drive/MyDrive/lectures_210923/PART_I_Intro/data/Lemonade2016.csv' lemonade = pd.read_csv(DATA_PATH) 위의 형식처럼 작성해도 된다.&quot;&quot;&quot;lemonade = pd.read_csv(DATA_PATH + 'data/Lemonade2016.csv')lemonade.info() &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB 데이터 확인하기123lemonade.head(5)# 데이터프레임의 상단 5개 데이터를 불러온다.# lemonade.head() =&gt; 이렇게 공백으로 넣을 경우 기본값이 5로 되어 있다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 0 7/1/2016 Park 97 67 70 90.0 0.25 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 123lemonade.tail(5)# 데이터프레임의 하단 5개 데이터를 불러온다.# lemonade.tail() =&gt; 이렇게 공백으로 넣을 경우 기본값이 5로 되어 있다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 27 7/27/2016 Park 104 68 80 99.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 29 7/29/2016 Park 100 66 81 95.0 0.35 30 7/30/2016 Beach 88 57 82 81.0 0.35 31 7/31/2016 Beach 76 47 82 68.0 0.35 1234567891011print(lemonade.info())&quot;&quot;&quot;데이터 셋의 정보를 볼 수 있다.데이터 셋 행은 총 31, 열은 7 개로 구성되어져 있다.&quot;&quot;&quot;print(lemonade.index)# 데이터프레임의 인덱스 확인print(lemonade.columns)# 데이터프레임의 컬럼(행)을 확인 할 수 있다.print(lemonade.values)# numpy 데이터의 값을 확인 할 수 있다. &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 32 entries, 0 to 31 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Date 31 non-null object 1 Location 32 non-null object 2 Lemon 32 non-null int64 3 Orange 32 non-null int64 4 Temperature 32 non-null int64 5 Leaflets 31 non-null float64 6 Price 32 non-null float64 dtypes: float64(2), int64(3), object(2) memory usage: 1.9+ KB None RangeIndex(start=0, stop=32, step=1) Index(['Date', 'Location', 'Lemon', 'Orange', 'Temperature', 'Leaflets', 'Price'], dtype='object') [['7/1/2016' 'Park' 97 67 70 90.0 0.25] ['7/2/2016' 'Park' 98 67 72 90.0 0.25] ['7/3/2016' 'Park' 110 77 71 104.0 0.25] ['7/4/2016' 'Beach' 134 99 76 98.0 0.25] ['7/5/2016' 'Beach' 159 118 78 135.0 0.25] ['7/6/2016' 'Beach' 103 69 82 90.0 0.25] ['7/6/2016' 'Beach' 103 69 82 90.0 0.25] ['7/7/2016' 'Beach' 143 101 81 135.0 0.25] [nan 'Beach' 123 86 82 113.0 0.25] ['7/9/2016' 'Beach' 134 95 80 126.0 0.25] ['7/10/2016' 'Beach' 140 98 82 131.0 0.25] ['7/11/2016' 'Beach' 162 120 83 135.0 0.25] ['7/12/2016' 'Beach' 130 95 84 99.0 0.25] ['7/13/2016' 'Beach' 109 75 77 99.0 0.25] ['7/14/2016' 'Beach' 122 85 78 113.0 0.25] ['7/15/2016' 'Beach' 98 62 75 108.0 0.5] ['7/16/2016' 'Beach' 81 50 74 90.0 0.5] ['7/17/2016' 'Beach' 115 76 77 126.0 0.5] ['7/18/2016' 'Park' 131 92 81 122.0 0.5] ['7/19/2016' 'Park' 122 85 78 113.0 0.5] ['7/20/2016' 'Park' 71 42 70 nan 0.5] ['7/21/2016' 'Park' 83 50 77 90.0 0.5] ['7/22/2016' 'Park' 112 75 80 108.0 0.5] ['7/23/2016' 'Park' 120 82 81 117.0 0.5] ['7/24/2016' 'Park' 121 82 82 117.0 0.5] ['7/25/2016' 'Park' 156 113 84 135.0 0.5] ['7/26/2016' 'Park' 176 129 83 158.0 0.35] ['7/27/2016' 'Park' 104 68 80 99.0 0.35] ['7/28/2016' 'Park' 96 63 82 90.0 0.35] ['7/29/2016' 'Park' 100 66 81 95.0 0.35] ['7/30/2016' 'Beach' 88 57 82 81.0 0.35] ['7/31/2016' 'Beach' 76 47 82 68.0 0.35]] 12345678910lemonade.describe()# 간단한 통계 정보를 보여주는 메서드다.# count : 컬럼별 데이터의 개수# mean : 데이터의 평균값# std : 표준편차# min : 최솟값# 25%, 50%, 75% ; 4분위 수# max : 최댓값 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Lemon Orange Temperature Leaflets Price Sold Revenue count 32.000000 32.000000 32.000000 31.000000 32.000000 32.000000 32.000000 mean 116.156250 80.000000 78.968750 108.548387 0.354687 196.156250 68.156250 std 25.823357 21.863211 4.067847 20.117718 0.113137 47.647976 24.645531 min 71.000000 42.000000 70.000000 68.000000 0.250000 113.000000 41.000000 25% 98.000000 66.750000 77.000000 90.000000 0.250000 164.750000 51.500000 50% 113.500000 76.500000 80.500000 108.000000 0.350000 189.000000 58.875000 75% 131.750000 95.000000 82.000000 124.000000 0.500000 226.000000 83.375000 max 176.000000 129.000000 84.000000 158.000000 0.500000 305.000000 134.500000 123lemonade.T# 데이터 프레임에서 인덱스와 컬럼을 바꾼형태 입니다.# 이때 주의할 점은 .T는 메서드가 아니기 때문에 .T() 형태로 사용하지 않습니다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 Date 7/1/2016 7/2/2016 7/3/2016 7/4/2016 7/5/2016 7/6/2016 7/6/2016 7/7/2016 NaN 7/9/2016 7/10/2016 7/11/2016 7/12/2016 7/13/2016 7/14/2016 7/15/2016 7/16/2016 7/17/2016 7/18/2016 7/19/2016 7/20/2016 7/21/2016 7/22/2016 7/23/2016 7/24/2016 7/25/2016 7/26/2016 7/27/2016 7/28/2016 7/29/2016 7/30/2016 7/31/2016 Location Park Park Park Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Beach Park Park Park Park Park Park Park Park Park Park Park Park Beach Beach Lemon 97 98 110 134 159 103 103 143 123 134 140 162 130 109 122 98 81 115 131 122 71 83 112 120 121 156 176 104 96 100 88 76 Orange 67 67 77 99 118 69 69 101 86 95 98 120 95 75 85 62 50 76 92 85 42 50 75 82 82 113 129 68 63 66 57 47 Temperature 70 72 71 76 78 82 82 81 82 80 82 83 84 77 78 75 74 77 81 78 70 77 80 81 82 84 83 80 82 81 82 82 Leaflets 90 90 104 98 135 90 90 135 113 126 131 135 99 99 113 108 90 126 122 113 NaN 90 108 117 117 135 158 99 90 95 81 68 Price 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.35 0.35 0.35 0.35 0.35 0.35 12345678910lemonade.sort_index(axis=0, ascending=True)# .sort_index() 메소드는 행과 열 이름을 정렬해준다.# 정렬 축을 설정할때는 axis를 사용한다# axis=0 : 인덱스를 기준# axis=1 : 컬럼을 기준# ascending은 정렬의 방향을 설정해준다.# ascending=True : 오름차순(기본값)# ascending=False : 내림차순 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 3 7/4/2016 Beach 134 99 76 98.0 0.25 0 4 7/5/2016 Beach 159 118 78 135.0 0.25 0 5 7/6/2016 Beach 103 69 82 90.0 0.25 0 6 7/6/2016 Beach 103 69 82 90.0 0.25 0 7 7/7/2016 Beach 143 101 81 135.0 0.25 0 8 NaN Beach 123 86 82 113.0 0.25 0 9 7/9/2016 Beach 134 95 80 126.0 0.25 0 10 7/10/2016 Beach 140 98 82 131.0 0.25 0 11 7/11/2016 Beach 162 120 83 135.0 0.25 0 12 7/12/2016 Beach 130 95 84 99.0 0.25 0 13 7/13/2016 Beach 109 75 77 99.0 0.25 0 14 7/14/2016 Beach 122 85 78 113.0 0.25 0 15 7/15/2016 Beach 98 62 75 108.0 0.50 0 16 7/16/2016 Beach 81 50 74 90.0 0.50 0 17 7/17/2016 Beach 115 76 77 126.0 0.50 0 18 7/18/2016 Park 131 92 81 122.0 0.50 0 19 7/19/2016 Park 122 85 78 113.0 0.50 0 20 7/20/2016 Park 71 42 70 NaN 0.50 0 21 7/21/2016 Park 83 50 77 90.0 0.50 0 22 7/22/2016 Park 112 75 80 108.0 0.50 0 23 7/23/2016 Park 120 82 81 117.0 0.50 0 24 7/24/2016 Park 121 82 82 117.0 0.50 0 25 7/25/2016 Park 156 113 84 135.0 0.50 0 26 7/26/2016 Park 176 129 83 158.0 0.35 0 27 7/27/2016 Park 104 68 80 99.0 0.35 0 28 7/28/2016 Park 96 63 82 90.0 0.35 0 29 7/29/2016 Park 100 66 81 95.0 0.35 0 30 7/30/2016 Beach 88 57 82 81.0 0.35 0 31 7/31/2016 Beach 76 47 82 68.0 0.35 0 12345lemonade.sort_values(by='Location')# 데이터 프레임의 내부에 있는 값으로 정렬할 수 있다.# 예시의 경우 Location을 기준으로 했다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price 15 7/15/2016 Beach 98 62 75 108.0 0.50 17 7/17/2016 Beach 115 76 77 126.0 0.50 16 7/16/2016 Beach 81 50 74 90.0 0.50 30 7/30/2016 Beach 88 57 82 81.0 0.35 14 7/14/2016 Beach 122 85 78 113.0 0.25 13 7/13/2016 Beach 109 75 77 99.0 0.25 12 7/12/2016 Beach 130 95 84 99.0 0.25 11 7/11/2016 Beach 162 120 83 135.0 0.25 10 7/10/2016 Beach 140 98 82 131.0 0.25 31 7/31/2016 Beach 76 47 82 68.0 0.35 8 NaN Beach 123 86 82 113.0 0.25 7 7/7/2016 Beach 143 101 81 135.0 0.25 6 7/6/2016 Beach 103 69 82 90.0 0.25 5 7/6/2016 Beach 103 69 82 90.0 0.25 4 7/5/2016 Beach 159 118 78 135.0 0.25 3 7/4/2016 Beach 134 99 76 98.0 0.25 9 7/9/2016 Beach 134 95 80 126.0 0.25 29 7/29/2016 Park 100 66 81 95.0 0.35 28 7/28/2016 Park 96 63 82 90.0 0.35 27 7/27/2016 Park 104 68 80 99.0 0.35 26 7/26/2016 Park 176 129 83 158.0 0.35 25 7/25/2016 Park 156 113 84 135.0 0.50 24 7/24/2016 Park 121 82 82 117.0 0.50 20 7/20/2016 Park 71 42 70 NaN 0.50 22 7/22/2016 Park 112 75 80 108.0 0.50 21 7/21/2016 Park 83 50 77 90.0 0.50 19 7/19/2016 Park 122 85 78 113.0 0.50 18 7/18/2016 Park 131 92 81 122.0 0.50 1 7/2/2016 Park 98 67 72 90.0 0.25 2 7/3/2016 Park 110 77 71 104.0 0.25 23 7/23/2016 Park 120 82 81 117.0 0.50 0 7/1/2016 Park 97 67 70 90.0 0.25 데이터 추가 삭제하기123lemonade['Sold'] = 0 print(lemonade.head(3))## 'Sold' 라는 기본값 0의 컬럼을 추가한다. Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 0 1 7/2/2016 Park 98 67 72 90.0 0.25 0 2 7/3/2016 Park 110 77 71 104.0 0.25 0 123lemonade['Sold'] = lemonade['Lemon'] + lemonade['Orange']print(lemonade.head(3))# 'Sold에 Lemon과 Orange 의 갯수를 합한 데이터를 넣어준다. Date Location Lemon Orange Temperature Leaflets Price Sold 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 123lemonade['Revenue'] = lemonade['Price'] * lemonade['Sold']print(lemonade.head(3))# 컬럼을 추가하는 과정을 생략할 수 있다. Date Location Lemon Orange ... Leaflets Price Sold Revenue 0 7/1/2016 Park 97 67 ... 90.0 0.25 164 41.00 1 7/2/2016 Park 98 67 ... 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 ... 104.0 0.25 187 46.75 [3 rows x 9 columns] 123456lemonade_column_drop = lemonade.drop('Sold', axis=1)print(lemonade_column_drop.head(3))lemonade_row_drop = lemonade_column_drop.drop(0, axis=0)print(lemonade_row_drop.head(3))#.drop을 이용해 추가한 컬럼,인덱스를 삭제할 수 있다. Date Location Lemon Orange Temperature Leaflets Price Revenue 0 7/1/2016 Park 97 67 70 90.0 0.25 41.00 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 Date Location Lemon Orange Temperature Leaflets Price Revenue 1 7/2/2016 Park 98 67 72 90.0 0.25 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 46.75 3 7/4/2016 Beach 134 99 76 98.0 0.25 58.25 데이터 인덱싱1print(lemonade[0:5]) Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 1 7/2/2016 Park 98 67 72 90.0 0.25 165 2 7/3/2016 Park 110 77 71 104.0 0.25 187 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 Revenue 0 41.00 1 41.25 2 46.75 3 58.25 4 69.25 123lemonade['Location'] == 'Beach'# 데이터 프레임에서 로케이션 컬럼 값이 Beach 일경우 True, 아닐경우 False를 반환 0 False 1 False 2 False 3 True 4 True 5 True 6 True 7 True 8 True 9 True 10 True 11 True 12 True 13 True 14 True 15 True 16 True 17 True 18 False 19 False 20 False 21 False 22 False 23 False 24 False 25 False 26 False 27 False 28 False 29 False 30 True 31 True Name: Location, dtype: bool 12print(lemonade[lemonade['Location'] == 'Beach'].head(5))# 이처럼 자신이 원하는 데이터가 있는 프레임만 찾을 수 있다. Date Location Lemon Orange Temperature Leaflets Price Sold \\ 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 Revenue 3 58.25 4 69.25 5 43.00 6 43.00 7 61.00 12print(lemonade.iloc[0:3, 0:2])# .iloc은 원하는 위치의 데이터를 표시할 수 있다. Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 123print(lemonade.loc[0:2, ['Date','Location']])# .loc는 iloc와 다르게 컬럼명을 직접적으로 설정해줘야한다.# 또한 loc는 지정한 범위 그대로 나온다 Date Location 0 7/1/2016 Park 1 7/2/2016 Park 2 7/3/2016 Park 1234print(lemonade.loc[lemonade['Revenue']&gt;45, ['Date','Revenue']].head(3))# .loc와 조건문을 결합하여 사용이 가능하다. 이 경우 Revenue 값이 45보다# 큰 데이터프레임에서 Date, Revenue 의 값을 출력한다 라는 의미다 Date Revenue 2 7/3/2016 46.75 3 7/4/2016 58.25 4 7/5/2016 69.25 '\\n.loc와 조건문을 결합하여 사용이 가능하다. 이 경우 Revenue 값이 45보다\\n큰 데이터프레임에서 Date, Revenue 의 값을 출력한다 라는 의미다\\n' 기존 데이터 전처리12print(lemonade.sort_values(by=['Temperature']).head(5))# Temperature 을 기준으로 오름차순 정렬 Date Location Lemon Orange Temperature Leaflets Price Sold \\ 0 7/1/2016 Park 97 67 70 90.0 0.25 164 20 7/20/2016 Park 71 42 70 NaN 0.50 113 2 7/3/2016 Park 110 77 71 104.0 0.25 187 1 7/2/2016 Park 98 67 72 90.0 0.25 165 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 Revenue 0 41.00 20 56.50 2 46.75 1 41.25 16 65.50 1234567lemonade.sort_values(by=['Temperature', 'Revenue'], ascending= False, inplace = True)print(lemonade.loc[:,['Date','Temperature', 'Revenue']].head(5))# Temperature, Revenue 두 컬럼을 기준으로 했지만 먼저 선언된 Temperature 을 기준# ascending= False 이므로 내림차순 정렬# inplace = True는 테이터프레임의 변경사항을 저장해주는 기능을 한다 Date Temperature Revenue 25 7/25/2016 84 134.50 12 7/12/2016 84 56.25 26 7/26/2016 83 106.75 11 7/11/2016 83 70.50 24 7/24/2016 82 101.50 123print(lemonade.groupby(by='Location').count())# 데이터들을 선언한 변수를 기준으로 그룹화 시켜준다.# 예시의 코드는 Location 컬럼이 포함된 다른 컬럼의 총 갯수를 표현한다. Date Lemon Orange Temperature Leaflets Price Sold Revenue Location Beach 16 17 17 17 17 17 17 17 Park 15 15 15 15 14 15 15 15 12print(lemonade.groupby('Location')['Revenue'].agg([max,min]))# 로케이션 별 최고 최소 수익을 나타내준다. max min Location Beach 95.5 43.0 Park 134.5 41.0 1234import numpy as nplemonade.mean()print(lemonade.groupby('Location')[['Revenue', 'Sold']].agg([max,min,np.mean]))# mean std sum 등 일부 함수는 .agg 안에서 넘파이에서 작성해야 한다. Revenue Sold max min mean max min mean Location Beach 95.5 43.0 58.988235 282 123 201.294118 Park 134.5 41.0 78.546667 305 113 190.333333 결측치12lemonade.isna()# 데이터 프레임의 결측치 값은 True 아닌것은 False로 반환한다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 False False False False False False False False False 12 False False False False False False False False False 26 False False False False False False False False False 11 False False False False False False False False False 24 False False False False False False False False False 10 False False False False False False False False False 28 False False False False False False False False False 8 True False False False False False False False False 30 False False False False False False False False False 31 False False False False False False False False False 5 False False False False False False False False False 6 False False False False False False False False False 18 False False False False False False False False False 23 False False False False False False False False False 7 False False False False False False False False False 29 False False False False False False False False False 22 False False False False False False False False False 27 False False False False False False False False False 9 False False False False False False False False False 19 False False False False False False False False False 4 False False False False False False False False False 14 False False False False False False False False False 17 False False False False False False False False False 21 False False False False False False False False False 13 False False False False False False False False False 3 False False False False False False False False False 15 False False False False False False False False False 16 False False False False False False False False False 1 False False False False False False False False False 2 False False False False False False False False False 20 False False False False False True False False False 0 False False False False False False False False False 1234null_del = lemonade# null_del=null_del.head() : 행 수 줄여서 하는 코딩#인덱스 명 제 코딩 12null_del.dropna()# 셀에 null 값이 하나라도 있을경우 해당 행을 삭제하여 출력한다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 12null_del.dropna(how='all')# 모든 행의 값이 null인 경우만 삭제하여 출력 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 12null_del.fillna(0)# null 값을 전부 0으로 대체해주는 메서드 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 8 0 Beach 123 86 82 113.0 0.25 209 52.25 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 20 7/20/2016 Park 71 42 70 0.0 0.50 113 56.50 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1234null_del.fillna({'Date': null_del['Date'].mean()})# 이러한 코드로 넣을 경우 Date 컬럼 값중 null 값은 Date의 평균 값으로 대체된다.# 하지만 오류가 난 것은, 현제 Date값이 정수,실수형이 아닌 # String 타입으로 작성되어 연산이 되지 않기 때문이다. --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-113-b3d91e8536a6&gt; in &lt;module&gt;() ----&gt; 1 null_del.fillna({'Date': null_del['Date'].mean()}) /usr/local/lib/python3.7/dist-packages/pandas/core/generic.py in stat_func(self, axis, skipna, level, numeric_only, **kwargs) 11473 return self._agg_by_level(name, axis=axis, level=level, skipna=skipna) 11474 return self._reduce( &gt; 11475 func, name=name, axis=axis, skipna=skipna, numeric_only=numeric_only 11476 ) 11477 /usr/local/lib/python3.7/dist-packages/pandas/core/series.py in _reduce(self, op, name, axis, skipna, numeric_only, filter_type, **kwds) 4247 ) 4248 with np.errstate(all=&quot;ignore&quot;): -&gt; 4249 return op(delegate, skipna=skipna, **kwds) 4250 4251 def _reindex_indexer(self, new_index, indexer, copy): /usr/local/lib/python3.7/dist-packages/pandas/core/nanops.py in _f(*args, **kwargs) 69 try: 70 with np.errstate(invalid=&quot;ignore&quot;): ---&gt; 71 return f(*args, **kwargs) 72 except ValueError as e: 73 # we want to transform an object array /usr/local/lib/python3.7/dist-packages/pandas/core/nanops.py in f(values, axis, skipna, **kwds) 127 result = alt(values, axis=axis, skipna=skipna, **kwds) 128 else: --&gt; 129 result = alt(values, axis=axis, skipna=skipna, **kwds) 130 131 return result /usr/local/lib/python3.7/dist-packages/pandas/core/nanops.py in nanmean(values, axis, skipna, mask) 561 dtype_count = dtype 562 count = _get_counts(values.shape, mask, axis, dtype=dtype_count) --&gt; 563 the_sum = _ensure_numeric(values.sum(axis, dtype=dtype_sum)) 564 565 if axis is not None and getattr(the_sum, &quot;ndim&quot;, False): /usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py in _sum(a, axis, dtype, out, keepdims, initial, where) 45 def _sum(a, axis=None, dtype=None, out=None, keepdims=False, 46 initial=_NoValue, where=True): ---&gt; 47 return umr_sum(a, axis, dtype, out, keepdims, initial, where) 48 49 def _prod(a, axis=None, dtype=None, out=None, keepdims=False, TypeError: can only concatenate str (not &quot;int&quot;) to str 12null_del.fillna({'Date' : '12/31/2021'})# 이럴 경우 딕셔너리로 칼럼명과 데이터를 넘겨주면 변경이 가능하다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 8 12/31/2021 Beach 123 86 82 113.0 0.25 209 52.25 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 123# 결측치를 알맞게 대체 했다면 적용하는 방법이다.null_del# 지금의 데이터는 null 갑이 대체되지 않았다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 8 NaN Beach 123 86 82 113.0 0.25 209 52.25 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 20 7/20/2016 Park 71 42 70 NaN 0.50 113 56.50 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00 1234567null_del.fillna({'Date' : '12/31/2021'},inplace=True)null_del.fillna(method='ffill')# inplace로 변경된 값을 데이터 프레임에 적용해주고, # method 매개변수는 앞에서 뒤의 데이터를 대체해주는 'ffill'# 뒤에서 대체해주는 'backfill 이 있다. .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Date Location Lemon Orange Temperature Leaflets Price Sold Revenue 25 7/25/2016 Park 156 113 84 135.0 0.50 269 134.50 12 7/12/2016 Beach 130 95 84 99.0 0.25 225 56.25 26 7/26/2016 Park 176 129 83 158.0 0.35 305 106.75 11 7/11/2016 Beach 162 120 83 135.0 0.25 282 70.50 24 7/24/2016 Park 121 82 82 117.0 0.50 203 101.50 10 7/10/2016 Beach 140 98 82 131.0 0.25 238 59.50 28 7/28/2016 Park 96 63 82 90.0 0.35 159 55.65 8 12/31/2021 Beach 123 86 82 113.0 0.25 209 52.25 30 7/30/2016 Beach 88 57 82 81.0 0.35 145 50.75 31 7/31/2016 Beach 76 47 82 68.0 0.35 123 43.05 5 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 6 7/6/2016 Beach 103 69 82 90.0 0.25 172 43.00 18 7/18/2016 Park 131 92 81 122.0 0.50 223 111.50 23 7/23/2016 Park 120 82 81 117.0 0.50 202 101.00 7 7/7/2016 Beach 143 101 81 135.0 0.25 244 61.00 29 7/29/2016 Park 100 66 81 95.0 0.35 166 58.10 22 7/22/2016 Park 112 75 80 108.0 0.50 187 93.50 27 7/27/2016 Park 104 68 80 99.0 0.35 172 60.20 9 7/9/2016 Beach 134 95 80 126.0 0.25 229 57.25 19 7/19/2016 Park 122 85 78 113.0 0.50 207 103.50 4 7/5/2016 Beach 159 118 78 135.0 0.25 277 69.25 14 7/14/2016 Beach 122 85 78 113.0 0.25 207 51.75 17 7/17/2016 Beach 115 76 77 126.0 0.50 191 95.50 21 7/21/2016 Park 83 50 77 90.0 0.50 133 66.50 13 7/13/2016 Beach 109 75 77 99.0 0.25 184 46.00 3 7/4/2016 Beach 134 99 76 98.0 0.25 233 58.25 15 7/15/2016 Beach 98 62 75 108.0 0.50 160 80.00 16 7/16/2016 Beach 81 50 74 90.0 0.50 131 65.50 1 7/2/2016 Park 98 67 72 90.0 0.25 165 41.25 2 7/3/2016 Park 110 77 71 104.0 0.25 187 46.75 20 7/20/2016 Park 71 42 70 104.0 0.50 113 56.50 0 7/1/2016 Park 97 67 70 90.0 0.25 164 41.00","link":"/2021/11/02/Pandas/"},{"title":"Statistics-Capter02","text":"1. 교차 분석 교차분석(chi-square test) 이란, 두 개의 변수가 질적인 명목척도일 때, 두 변수간의 빈도 비교를 통해 연관성을 파악하기 위해 사용하는 분석법을 의미한다. 이러한 교차분석을 진행할 때 대립가설과 귀무가설을 설정한다. 귀무가설 : 모집단의 특성에 대해 옳다고 제안하는 잠정적인 가설 대립가설 : 귀무가설이 거짓일 경우 대안적으로 참이 되는 가설 이러한 교차분석을 설명하기 위해 알아야 하는 것은 카이제곱 값과 유의확률 이다. 카이제곱 값은 χ2 = Σ (관측값 - 기댓값)2 / 기댓값 으로 표현한다. 유의확률(p)은 귀무 가설이 맞다고 가정했을 때 얻은 결과보다 극단적인 결과가 실제로 관측될 확률을 뜻한다. 통상적으로 유의 확률은 0.05, 0.01을 기준으로 하는것이 관례이며 기준보다 낮은 값이 나올경우 유의미 라고 표현한다. 이러한 교차 분석을 설명하기 위해 SPSS에서 예시를 들어 설명하겠다. 2. SPSS 교차 분석 예시 변수 설정 교차분석의 경우 독립변수와 종속변수의 구분이 없다.1변수 : 성별, 연령대 가설 설립 12귀무가설 : 성별과 연령대는 연관성이 없다대립가설 : 성별과 연령대는 연관성이 있다. SPSS 실행 결과 해석 위 사진으로 보면 10대~40대까지 연령대를 나눠서 총 15케이스를 교차분석한 결과 카이제곱 값은 2.277, 유의확률은 0.517이 나왔다. 이러한 경우 유의확률 기준치인 0.05보다 크기 때문에 대립가설을 기각하고 귀무가설을 체택한다. 결론 : 성별과 연령대는 연관성이 없다","link":"/2021/11/02/Statistics-Capter02/"},{"title":"Colab-github","text":"1. 구글 Colab에서 작성한 파일 github blog에 업로드 하기 Colab에서 파일 저장하기 goolge colab에서 깃헙 블로그에 파일을 저장하기 위해선 먼저 colab에서 파일을 .ipynb 형식으로 파일을 다운로드 해준다. Anaconda 실행 Anaconda Navigator을 관리자 권한으로 실행 JupyterLab Lunch 클릭해서 쥬피터랩을 실행한다. 쥬피터랩에서 colab에서 작성한 .ipynb 형식의 파일을 찾아 클릭한다. 위 화면처럼 .ipynb 형식 파일을 Markdown 파일 형식으로 저장한다. 쥬피터랩에서 다운받은 .md 파일을 블로그 폴더 source - _post 폴더에 넣고 파이참으로 파일을 연다. hexo server 로 파일이 제대로 불러와지는지 확인하고 오류가 없다면 hexo generate hexo deploy를 실행한다.","link":"/2021/11/02/Colab-github/"},{"title":"github-blog","text":"1. node.js 설치1. node.js 설치 클릭 설치할때 path 경로를 설정을 꼭 해줘야한다. 2.git bash에서 node설치 확인 git bash 실행 입력창에 node -v 입력 버전이 확인되었다면 npm install -g hexo-cli 입력 2. 블로그 파일 설정1. 원하는 경로에 git bash를 이용해 폴더를 새로 만든다. hexo init foldername 입력 폴더가 생성되었다면 hexo 서버 연결을 위한 설정을 파이참으로 해준다 npm install npm install hexo-server --save npm install hexo-deployer-git --save2. git hub 사이트에 새로운 파일은 리퍼지토리 한다. 설정한 폴더명으로 리퍼지토리를 진행한다. echo &quot;# dsadsa&quot; &gt;&gt; README.md, git init 까지 입력하고 git add . 후 나머지를 작성해준다. 리퍼지토리가 제대로 이루어졌는지 확인한다. 3. github.io 파일 설정1. git hub에서 username.github.io로 새로운 파일을 리퍼지토리 해준다 _config.yml 폴더에서 설정을 진행 _config.yml에서 title 은 블로그의 제목을 설정 url 에서는 https://username.github.io으로 url값을 설정 이때 https://로 설정하지 않을 경우 `hexo deploy` 를 했을 때 404오류가 발생 할 수 있다. # Deployment 아래의 코드를 입력한다. deploy: type: git repo: https://github.com/rain0430/rain0430.github.io.git branch: main 2. github에 배포하기 git bash 에 hexo generate hexo server 입력 hexo server 입력 후 터미널에 localhost:4000를 클릭하여 블로그가 정상적으로 출력되는지 확인한다. 확인후 control + c를 눌러 서버를 종료한 후, hexo deploy 를 입력한다. 본인이 설정한(usernaem,github.io)를 주소창에 입력하여 정상작동을 확인한다. 블로그가 작성되는 시간이 있기 때문에 1분 정도 404 오류가 뜰 수 있다. 4. 블로그 테마 적용하기1. 블로그 테마 선택하기 블로그 테마에는 다양한 종류가 있으며 git hub를 확인하여 업데이트가 최신으로 이루어지는 테마를 선택하는 것이 좋다. 그 중 예시로 icarus의 설치를 해보겠다. 2. 블로그 테마 설치하기 터미널에 npm install -S hexo-theme-icarus 입력하여 icarus 설치 _config.yml 에서 theme: landscape 부분을 주석 처리후 theme: icarus 입력 그 후 hexo generate 와 hexo server를 실행하면 에러가 발생하는 것을 볼 수 있다. 터미널에 npm install --save bulma-stylus@0.8.0 hexo-renderer-inferno@^0.1.3 을 입력하고 다시 실행 로컬에서 테마가 정상 작동하는 것을 확인하고 hexo deploy를 진행해 준다. 추가 정보는 고든의 깃허브에서 확인 가능하다. 이건 귀여운 고양이 사진이다","link":"/2021/11/02/github-blog/"},{"title":"Statistics-Capter03","text":"1. 피어슨 상관분석 피어슨(Pearson) 상관 분석(correlation analysis) 이란 다른 용어로 선형상관분석을 줄인 단어로 두 변수간의 어떤 선형적 또는 비선형적 관계를 갖고 있는지 분석하는 방법이다. 선형이란 두 변수 사이의 밀접성, 강도, 방향을 요약하여 나타내는 수치로,-1 &lt;= r &lt;=1 의 값을 가지는데, 이때 두 변수간의 상관관계(r)가 0이면, 이것은 ‘두 변수간의 상관이 없다는 뜻이 아닌 선형관계가 아니다’ 라는 뜻이다. 선형 그래프는 크게 3가지 종류로 나누어진다 이러한 특징은 다른 의미로 상관 분석은 변수간의 인과관계를 파악하는데 사용하는 것은 잘못되었음을 의미한다. 이러한 피어슨 상관분석을 설명하기 위해 SPSS에서 예시를 들어 설명하겠다. 2. 피어슨 상관분석 예시 변수 설정1변수 : 폭력, 공감, 정서, 심리 가설 설립 피어슨 상관분석은 단순히 두 변수간의 상관관계 유무와 정도를 파악할 뿐, 인과관계를 파악하는 것이 아니므로 가설을 따로 설립하지 않는다. SPSS 실행 결과 해석 위의 표에서 Pearson 상관의 값을 보면 음수와 양수로 나눠져 있음을 볼 수 있다.두 변수간의 부호가 +, 양수라면 두 변수가 정적 상관관계(우상향 선형)을 가지고 있음을 의미하며, 음수라면 부적 상관관계(우하향 선형) 형태임을 뜻한다. 표의 결과를 보면 공감과 심리간의 상관 관계에서 r=0.899, p=0.000 으로 가장 높은 정적 상관관계를 나타내고 있으며,정서와 심리는 r=0.605, p=0.000으로 상대적으로 낮은 정적 상관관계를 보여주고 있다.- 폭력과 공감은 r=-0.295, p=0.000으로 가장 높은 부적 상관관계를 보이며, 폭력과 정서는r=-0.243 으로 상대적으로 낮다. 피어슨 상관분석은 이처럼 두 변수간의 관계의 유무를 나타낼 뿐이고, 이와 관련된 인과관계를 파악하기 위해서는 회귀분석을 이용 할 수 있다.","link":"/2021/11/02/Statistics-Capter03/"},{"title":"Statistics-Capter01","text":"변수(Variable) 란, 연구자가 연구하고자 하는 개념을 뜻한다. ex)성별 나이 학벌 수면 시간 등.. 변수는 위치와 역활에 따라 크게 독립변수, 종속변수, 제3변수로 개념이 나눠진다. 독립변수(Independent Variable)이란 어떤 현상에 원인의 역할을 하는 변수를 의미한다. 종속변수((Dependent Variable)이란 원인에 의해 결과가 달라지는 변수를 의미한다. 2. 척도의 개념 척도(Scale)이란 변수를 측정 가능토록 수치화한 것 을 의미한다. 척도는 크게 명목척도, 등간척도, 서열척도, 비율척도가 있다. 측정 수준 척도 성질 예시 연산 분류 명목척도 (Nominal scale) 고유함 이름, 성별 비가산 집합 서열척도 (ordinal scale) 순서 순위, 서열 비가산 집합 수량 등간척도 (interval scale) 순서, 간격 온도, 지능지수 사칙연산 중 가산가능 비율척도 (Ratio scale) 순서, 간격, 비율 자연수, 몸무게 사칙연산 가능 분석을 진행할 때 독립변수와 종속변수가 각각 어떠한 척도로 구성되어 있는지에 따라 다른 분석법이 사용된다. 그럼으로 분석을 진행하기 전, 변수가 어떠한 척도로 구성되어 있는지 반드시 확인해야만 한다.","link":"/2021/11/02/Statistics-Capter01/"},{"title":"Python 문법 1","text":"Hello World1print(&quot;Hello World&quot;) Hello World 주석처리123456# 한 줄 주석처리 할때는 #을 붙인다&quot;&quot;&quot;여러 줄을 주석처리 할 때는 큰 따옴표 or 작은 따옴표 세게 사이에 사용한다. 줄의 수는 상관이 없다&quot;&quot;&quot;print(&quot;주석처리&quot;) 주석처리 #변수의 종류 1234567891011num_int = 1print(type(num_int))num_float = 0.2print(type(num_float))bool_true = Trueprint(type(bool_true))none_x = Noneprint(type(none_x)) &lt;class 'int'&gt; &lt;class 'float'&gt; &lt;class 'bool'&gt; &lt;class 'NoneType'&gt; 사칙 연산123456789a = 5b = 4print('a + b = ', a+b)print('a - b = ', a-b)print('a * b = ', a*b)print('a / b = ', a/b)print('a // b = ', a//b)print('a % b = ', a%b)print('a ** b = ', a**b) a + b = 9 a - b = 1 a * b = 20 a / b = 1.25 a // b = 1 a % b = 1 a ** b = 625 123456789c = 4.0d = 6.0print('c + d =', c+d)print('c - d =', c-d)print('c * d =', c*d)print('c / d =', c/d)print('c // d =', c//d)print('c % d =', c%d)print('c ** d =', c**d) c + d = 10.0 c - d = -2.0 c * d = 24.0 c / d = 0.6666666666666666 c // d = 0.0 c % d = 4.0 c ** d = 4096.0 문자열과 정수열 연산12345678# 문자열에 숫자를 더하기 위해선 어떻게 해야할까?a = 1004b = &quot;천사&quot;c = a+bprint(c)#위의 결과처럼 문자열과 숫자를 단순히 연산자로 더해줄 경우 오류가 발생한다 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-108-fe25ce2f05b3&gt; in &lt;module&gt;() 2 a = 1004 3 b = &quot;천사&quot; ----&gt; 4 c = a+b 5 6 print(c) TypeError: unsupported operand type(s) for +: 'int' and 'str' 1234567# 이 문제를 해결하기 위해선 숫자(정수형, 실수형)을 문자형으로 바꿔줄 필요가 있다.a = str(1004) #정수 1004를 str()로 묶어 문자형으로 변형해주었다.b = &quot;천사&quot;c = a+bprint(c) 1004천사 1234567# 그렇다면 + 가 아닌 다른 연산자인 * 를 사용하면 어떻게 될까?a = str(1004)b = &quot;천사&quot;c = a*bprint(c) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-110-b55996f7f08d&gt; in &lt;module&gt;() 3 a = str(1004) 4 b = &quot;천사&quot; ----&gt; 5 c = a*b 6 7 print(c) TypeError: can't multiply sequence by non-int of type 'str' 123456789101112# 위의 결과처럼 오류가 뜨지만, 이것이 문자형에 * 연산자를 사용하지 못함을 의미하는 것은 아니다.a = str(1004)b = &quot;천사&quot;c = a+bprint(b*3)# 위 결과처럼 &quot;천사&quot; 을 * 연산자를 사용해 3번 출력이 가능한 것을 확인 할 수 있다.#응용print((c+b)*3)#이런식으로 복합 연산도 가능하다. 천사천사천사 1004천사천사1004천사천사1004천사천사 논리형 연산자1234print(True and True)print(True and False)print(False and True)print(False and False) True False False False 1234print(True or True)print(True or False)print(False or True)print(False or False) True True True False 비교 연산자123456print(4 &gt; 3)print(4 &lt; 3)print(4 &gt;= 3)print(4 &lt;= 3)print(4 &gt; 4)print(4 &gt;= 4) True False True False False True 논리형 &amp; 비교 연산자 응용1234# input(&quot;숫자를 입력하세요&quot;)data = input(&quot;숫자를 입력하세요&quot;)data2 = int(data)print(type(data2)) 숫자를 입력하세요100 &lt;class 'int'&gt; 12345678num1 = int(input(&quot;첫번째 숫자를 입력하세요: &quot;))num2 = int(input(&quot;두번째 숫자를 입력하세요: &quot;))num3 = int(input(&quot;세번째 숫자를 입력하세요: &quot;))num4 = int(input(&quot;네번째 숫자를 입력하세요: &quot;))var1 = num1 &gt;= num2var2 = num3 &lt; num4print(var1 and var2) 첫번째 숫자를 입력하세요: 5 두번째 숫자를 입력하세요: 4 세번째 숫자를 입력하세요: 3 네번째 숫자를 입력하세요: 2 False String12print(&quot;'Hello, world!'&quot;)print('&quot;Hello, world!&quot;') String Operators123str1 = &quot;Hello &quot;str2 = &quot;World &quot;print('str1 + str2 = ', str1 + str2) str1 + str2 = Hello World 12greet = str1 + str2print('greet * 3 = ', greet * 3) greet * 3 = Hello World Hello World Hello World Indexing12greeting = &quot;Hello Kaggle&quot;print(greeting[6]) Slicing 123456greeting = &quot;Hello Kaggle&quot;print(greeting[:])print(greeting[6:])print(greeting[:6])print(greeting[3:8])print(greeting[0:9:2]) Hello Kaggle Kaggle Hello lo Ka HloKg 1234greeting[13]&quot;&quot;&quot;정해진 문자열 보다 더 큰 배열값이 들어갔기 때문에 null값이 출력되어야 하기 때문에 오류가 나온다&quot;&quot;&quot; --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-16-e484aa72e855&gt; in &lt;module&gt;() ----&gt; 1 greeting[13] 2 &quot;&quot;&quot; 3 정해진 문자열 보다 더 큰 배열값이 들어갔기 때문에 null값이 출력되어야 하기 때문에 오류가 나온다 4 &quot;&quot;&quot; IndexError: string index out of range 리스트1234567891011121314e = [['apple','banana','cherry'],1]print(e[0][2])a = [] # 빈 리스트a_func = list() #list()함수로도 빈 리스트를 만들 수 있다.b = [1] # 숫자도 요소가 될 수 있다.c = ['apple'] # 문자열도 요소가 될 수 있다d = [1, 2, ['apple']] # 리스트 안에 리스트를 요소로 넣을 수 있다.print(a)print(a_func)print(b)print(c)print(d) cherry [] [] [1] ['apple'] [1, 2, ['apple']] 123456a = [1, 2, 3]# index [[0], [1], [2]]print(a[0]) # 첫번째 요소print(a[1]) # 두번째 요소print(a[2]) # 세번째 요소print(a[-1]) 1 2 3 3 123456a = [['apple','banana','cherry']]print(a[0]) # 리스트 내의 리스트print(a[0][0]) # 리스트 내의 리스트의 첫번째 문자열print(a[0][0][3]) # 리스트 내의 리스트의 첫번째 문자열 'apple' 중 첫번째 인덱스print(a[0][1]) # 리스트 내의 리스트의 두번째 문자열 ['apple', 'banana', 'cherry'] apple l banana 12345678910111213a = [1,2,3,4,5,6,7,8,9,10]b = a[:4] # 인덱스 0부터 3까지c = a[1:4] # 인덱스 1부터 3까지d = a[0:7:2] # 인덱스 0부터 6까지 인덱스 2씩 건너 띄우기e = a[::-1] # 리스트 a의 역순f = a[::2] # 리스트 전체구간에서 인덱스 2씩 건너띄우기print(&quot;a[:4]&quot;, b)print(&quot;a[1:4]&quot;, c)print(&quot;a[0:7:2]&quot;, d)print(&quot;a[::-1]&quot;, e)print(&quot;a[::2]&quot;, f) a[:4] [1, 2, 3, 4] a[1:4] [2, 3, 4] a[0:7:2] [1, 3, 5, 7] a[::-1] [10, 9, 8, 7, 6, 5, 4, 3, 2, 1] a[::2] [1, 3, 5, 7, 9] 12345a = ['alice', 'bob', 'cat']b = ['apple', 'banana', 'cherry']c = a+bprint(c) ['alice', 'bob', 'cat', 'apple', 'banana', 'cherry'] 123456a = ['a','b','c']b = a*3c = a*0print(&quot;a * 3:&quot;, b)print(&quot;a * 0:&quot;, c) a * 3: ['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c'] a * 0: [] '\\n문제에서 제공된 수의 범위를 보면 5부터 -9 까지 -2 씩 줄어드는 걸 알 수 있다. \\nlist에서 range 메소드를 이용할 경우 ()안에 각각 값의 의미는 ((a,b,c) 일 경우 a=시작 숫자/b=끝 숫자/c= 숫자들의 증감폭) 이다.\\n' 리스트 도장 연습문제 range를 이용해 [5, 3, 1, -1, -3, -5, -7, -9]가 출력되게 만드세요 12345678a = list(range(5,-10,-2))print(a)&quot;&quot;&quot;문제에서 제공된 수의 범위를 보면 5부터 -9 까지 -2 씩 줄어드는 걸 알 수 있다. list에서 range 메소드를 이용할 경우 ()안에 각각 값의 의미는 ((a,b,c) 일 경우 a=시작 숫자/b=끝 숫자/c= 숫자들의 증감폭) 이다.&quot;&quot;&quot; [5, 3, 1, -1, -3, -5, -7, -9] '\\n문제에서 제공된 수의 범위를 보면 5부터 -9 까지 -2 씩 줄어드는 걸 알 수 있다. \\nlist에서 range 메소드를 이용할 경우 ()안에 각각 값의 의미는 ((a,b,c) 일 경우 a=시작 숫자/b=끝 숫자/c= 숫자들의 증감폭) 이다.\\n' 리스트 값 추가하기1234a = [0,1,2]a[1] = &quot;b&quot;# a의 배열값 1을 &quot;b&quot;로 바꿔준다print(a) [0, 'b', 2] 리스트값 추가하기1234567a = [100, 200, 300]a.append(400)print(a)# 맨처음 a 배열에 400을 뒤에 추가로 넣어준다.a.append([500,600])print(a)# 400이 추가된 배열에 또 추가로 [500,600] 의 배열을 추가로 넣어준다. [100, 200, 300, 400] [100, 200, 300, 400, [500, 600]] 12345a = [1,2,3]a.extend([40,500])print('a.extend([40,500]) result')print(a) #append와 다르게 추가를 배열로 넣어줬지만, extend는 배열과 배열을 합쳐주는 거기 때문에 하나의 배열로 합쳐져 출력된다. a.extend([40,500]) result [1, 2, 3, 40, 500] 123456a = [0,1,2]a.insert(4,5)a.insert(4,&quot;HI&quot;)print(a)# insert에서 ()안에서 앞의 숫자는 배열의 순서를 지정해주고, 뒤의 숫자는 배열에 들어갈 값을 의미한다. [0, 1, 2, 5, 'HI'] 1234567891011121314a = [0,1,2,3]a[0:0] = [100,200]print(a)# 시작과 끝의 범위보다 큰 수를 덮어쓰는 예시b = [0,1,2,3]b[1:1] = [100,200,300,400] print(b)# 시작과 끝의 범위가 작을때의 예시c = [0,1,2,3]b[1:2] = [100,200,300,400] print(c)# 잘 사용하지 않는다. [100, 200, 0, 1, 2, 3] [0, 100, 200, 300, 400, 1, 2, 3] [0, 1, 2, 3] 리스트 값 삭제하기12345678910a =[1,2,1,2]#리스트의 첫번째 1이 삭제a.remove(1)print(a)#리스트의 두번째 1이 삭제a.remove(1)print(a)# remove를 이용하면 배열에 순서대로 삭제가 가능하다. 이때, 배열에 존재하지 않는 값을 넣을 경우 오류가 발생한다. [2, 1, 2] [2, 2] 12345678910a = [0,4,2,3,4,5,6,7,8,9]# 1 삭제del a[1]print(a)# del은 배열에 위치를 지정해서 삭제가 가능하다.b = [0,1,2,3,4,5,6,7,8,9]# 범위로 삭제del b[1:3] #list는 항상 시작하는 index부터, 종료하는 n의 n-1까지의 범위를 잡아줍니다.print(b) [0, 2, 3, 4, 5, 6, 7, 8, 9] [0, 3, 4, 5, 6, 7, 8, 9] 123456#인덱스를 지정한 pop()a = [1,1,2,3,4]r = a.pop(0)# 윈도우의 잘라서 붙여넣기를 생각하면 쉽다.print(a)print(r) [1, 2, 3, 4] 1 123456#인덱스를 지정하지 않은 pop()b = ['a','b','c','d',]x = b.pop()# 인덱스를 지정하지 않을 경우 배열의 가장 끝의 값을 가져온다.print(b)print(x) ['a', 'b', 'c'] d 그 외 유용한 메서드12345a = [0,1,2,3]print(a)# 배열의 모든 값을 삭제하는 메서드a.clear()print(a) [0, 1, 2, 3] [] 123a = [&quot;Gold&quot;, &quot;Gold&quot;, &quot;Silver&quot;, &quot;Silver&quot;]print(&quot;Silver가 처음 등장하는 인덱스 번호&quot;, a.index(&quot;Silver&quot;))# 해당 값이 들어있는 배열의 번호를 출력하는 메서드 Silver가 처음 등장하는 인덱스 번호 2 12345678910a = [1, 4, 5, 2, 3]b = ['a', 'c','f','b','d','e']a.sort()print(&quot;sort():&quot;,a)# 무작위로 나열된 배열의 값을 내림차순으로 정렬하는 메서드b.sort(reverse=True)print(&quot;sort(reverse=True):&quot;, b)# 무작위로 나열된 배열의 값을 오름차순으로 정렬하는 메서드# 알파벳 순서도 가능하다. sort(): [1, 2, 3, 4, 5] sort(reverse=True): ['f', 'e', 'd', 'c', 'b', 'a'] 12345b = [4,3,2,'a']b.sort()print(b)# 단, 문자열과 정수를 혼합해서 정렬하는것은 불가능하다. --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-71-1624da3f09a9&gt; in &lt;module&gt;() 1 b = [4,3,2,'a'] 2 ----&gt; 3 b.sort() 4 print(b) TypeError: '&lt;' not supported between instances of 'str' and 'int' 튜플1234567891011tuple1 = (0) # 끝에 콤마(,)를 붙이지 않았을 때tuple2 = (0,) # 끝에 콤마(,)를 붙여줬을 때tuple3 = 0,1,2print(tuple1)print(tuple2)print(tuple3)print(type(tuple1)) # 콤마(,)를 붙여주지 않으면 튜플이 아닙니다.print(type(tuple2)) # 콤마(,)를 붙여주어야 튜플 자료형 입니다.print(type(tuple3)) # 여러개의 값 일경우 괄호를 없애주어도 튜플 자료형 입니다. 0 (0,) (0, 1, 2) &lt;class 'int'&gt; &lt;class 'tuple'&gt; &lt;class 'tuple'&gt; 12a = (0,1,2,3,'a')del a[1] --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-74-e9d08d739f62&gt; in &lt;module&gt;() 1 a = (0,1,2,3,'a') ----&gt; 2 del a[1] TypeError: 'tuple' object doesn't support item deletion 12a = (0,1,2,3,'a')a[1]='t' --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-75-04fb068f82e0&gt; in &lt;module&gt;() 1 a = (0,1,2,3,'a') ----&gt; 2 a[1]='t' TypeError: 'tuple' object does not support item assignment 튜플은 리스트처럼 요소를 저장할 수 있지만, 리스트와 다르게 요소를 추가, 삭제, 변경 할 수 없다 튜플 인덱싱 및 슬라이싱 하기1234t = (0,1,2,'b',4)print(t[1])print(t[3]) 1 b 1234t = (0,1,2,3,4)print(t[2:]) #시작만 설정할 경우 시작 순서부터 배열 끝까지 값을 가져온다.print(t[0:2]) #시작과 끝을 지정할 경우 리스트와 마찬가지로 끝 지점은 설정 한 값보다 하나 작게 출력된다. (2, 3, 4) (0, 1) 튜플의 더하기 및 곱셈 연산자 사용123456t1 = (0,1,2,3,4)t2 = ('a','b','c')t3 = t1+t2print(t1+t2)print(t3)#튜플의 요소를 삭제, 추가, 변경은 불가능하지만, 튜플과 튜플을 합치는 것은 가능하다. (0, 1, 2, 3, 4, 'a', 'b', 'c') (0, 1, 2, 3, 4, 'a', 'b', 'c') 1234t1 = ('a',1)print(t1*0)print(t1*3)# 튜플에 지정된 요소에 곱하기를 하는 것이 아닌, 요소 자체의 갯수를 늘려준다. () ('a', 1, 'a', 1, 'a', 1) 딕셔너리1234567dic = {'teacher':'alice', 'class': 5, 'studentid': '15', 'list':[1,2,3]}print(dic['teacher'])print(dic['class'])print(dic['list'])# 값을 : 을 통해 서로 연관하여 만든다 alice 5 [1, 2, 3] 1234dic = {'teacher':'alice', 'class': 5, 'studentid': '15', 'list':[1,2,3]}print(dic['real'])# 따로 지정해주지 않으면 나오지 않는다. --------------------------------------------------------------------------- KeyError Traceback (most recent call last) &lt;ipython-input-82-4c77a57c3172&gt; in &lt;module&gt;() 1 dic = {'teacher':'alice', 'class': 5, 'studentid': '15', 'list':[1,2,3]} ----&gt; 2 print(dic['real']) 3 4 # 따로 지정해주지 않으면 나오지 않는다. KeyError: 'real' 1234a = {'name': 'bob', 'job': 'farmer', 'age': 35}a.keys()# keys() 를 사용하면 연관지은 변수 명을 호출한다. dict_keys(['name', 'job', 'age']) 123a = {'name': 'bob', 'job': 'farmer', 'age': 35}a.values()# values() 를 사용하면 연관지어진 변수를 호출한다. dict_values(['bob', 'farmer', 35]) 1234a = {'name': 'chris', 'job': 'painter', 'age': 30}print(a.get('name')) # 일반적인 딕셔너리로 연관지어진 값을 가져온다.print(a.get('dinner')) # 따로 지정해주지 않았음으로 null값이기 때문에 None이 나온다print(a.get('dinner', 'empty')) # 두 변수 모두 따로 지정해주지 않았지만, 첫번째 선언한 dinner가 null이기 때문에 뒤에 선언한 변수가 추가로 출력된다 chris None empty 집합 연산자12345678s = {}print(type(s))s = set()print(type(s))s = {1,2,3}print(type(s)) &lt;class 'dict'&gt; &lt;class 'set'&gt; &lt;class 'set'&gt; 12345678a = {1,3,5}b = {2,4,6}c = a|bd = a.union(b)print(&quot;a|b:&quot;, c)print(&quot;a.union(b)&quot;, d)# 두 집합을 합쳐주는 방법 a|b: {1, 2, 3, 4, 5, 6} a.union(b) {1, 2, 3, 4, 5, 6} 123456789101112a = {1,3,5}b = {2,4,6}c = a&amp;bprint(c)e = {1,2,5}f = {2,3,5}g1 = e&amp;fg2 = e.intersection(f)print(&quot;e&amp;f:&quot;, g1)print(&quot;e.intersection(f):&quot;, g2)# 두 집합의 교집합을 출력하는 방법 12345678a = {1,3,5}b = {2,4,5}c1 = a-bc2 = a.difference(b)print(&quot;a-b:&quot;, c1)print(&quot;a.difference(b)&quot;, c2)# a와 b의 교집합을 제외하고난 a 집합의 값만 출력하는 방법 12345678a = {1,2,3,4,5}b = {3,4,5,6,7}c1 = a^bc2 = a.symmetric_difference(b)print(&quot;a^b&quot;, c1)print(&quot;a.symmetric_difference(b)&quot;, c2)# a와 b집합의 차집합을 출력하는 방법 if 조건문12345678910a = 1if a&gt;5: print('a is bigger than 5')elif a &gt; 0: print(&quot;a is bigger than 0 but a is smaller than 5 &quot;)else: print(&quot;a is negative&quot;) a is bigger than 0 but a is smaller than 5 1234567x = 10 if x == 10: print('x에 들어있는 숫자는') print('10입니다.') # unexpected indent 에러 발생 #파이썬의 경우 들여쓰기가 문법으로 설정되어 있다. 위 코드의 경우 코드의 경우 들여쓰기 오류가 발생한 것이다. File &quot;&lt;ipython-input-114-3d11f098459b&gt;&quot;, line 5 print('10입니다.') # unexpected indent 에러 발생 ^ IndentationError: unexpected indent 123456789101112x = 10 if x == 10: print('x에 들어있는 숫자는') #들여쓰기 4칸 print('10입니다.') &quot;&quot;&quot;이처럼 파이썬의 if문 문법의 기본 형태는if a == n; print(dsadasd)형식으로 if 문 다음 줄은 4칸의 들여쓰기를 해야한다.다른 의미로는 : 로 끝나고 난 다음 줄은 반드시 들여쓰기를 해야한다.&quot;&quot;&quot; x에 들어있는 숫자는 10입니다. '\\n이처럼 파이썬의 if문 문법의 기본 형태는\\nif a == n;\\n print(dsadasd)\\n형식으로 if 문 다음 줄은 4칸의 들여쓰기를 해야한다.\\n다른 의미로는 : 로 끝나고 난 다음 줄은 반드시 들여쓰기를 해야한다.\\n' 반복문12for i in range(10): print(&quot;Hello World&quot;) Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World Hello World 123456789a = &quot;Kaggle&quot;for x in a: print(x) if x == 'g': break #a에 들어간 Kaggle에서 g의 순서가 나올때까지 반복해서 g가 나올경우 g를 x에 넣고 출력한다. K a g 12345alphabets = ['A', 'B', 'C']for index, value in enumerate(alphabets): # 시퀀스 자료형이 들어간다 print(index, value) # 알파벳 벨류에 들어간 배열이 끝날때 까지 전부 출력한다. 0 A 1 B 2 C","link":"/2021/11/02/Python01/"},{"title":"numpy 기초문법","text":"numpy 기초12import numpy as np 12data1 = [1,2,3,4,5]data1 [1, 2, 3, 4, 5] 12data2 = [1,2,3,4,5]data2 [1, 2, 3, 4, 5] 12arr1 = np.array(data1)arr1 array([1, 2, 3, 4, 5]) 12arr1.shape# 넘파이의 배열의 길이를 튜플 형식으로 나타내준다. (5,) 12arr1.dtype# 넘파이 배열의 값의 자료형을 나타내준다. dtype('int64') 123arr2 = np.array([1,2,3,4,5]) arr2# 1차원 데이터 array([1, 2, 3, 4, 5]) 12arr3 = np.array(data2)arr3 array([1, 2, 3, 4, 5]) 1234arr4 = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])arr4# 2차원 데이터 array([[ 1, 2, 3], [ 4, 5, 6], [ 7, 8, 9], [10, 11, 12]]) 1arr4.shape (4, 3) 123array5 = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])array5.shape# 3차원 데이터 (2, 2, 2) 넘파이 기본 함수12np.arange(10)# 배열을 생성하는 함수, 지정해준 값-1 까지 배열을 생성해준다. array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 1234np.arange(3,10)# 범위를 지정 할 수 있다.np.arange(0,10,2)# 범위를 지정해 주고 동시에 배열값의 증감폭도 지정해 줄 수 있다. array([0, 2, 4, 6, 8]) 12np.zeros(10)# 값이 0으로 이루어진 배열을 생성한다. array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) 12np.ones(9)# 값이 1로 이루어진 배열을 생성한다. array([1., 1., 1., 1., 1., 1., 1., 1., 1.]) reshape1234ones_array = np.ones((3,4), dtype='int32')print(ones_array)print(&quot;Data Type is:&quot;, ones_array.dtype)print(&quot;Data Shape is:&quot;, ones_array.shape) [[1 1 1 1] [1 1 1 1] [1 1 1 1]] Data Type is: int32 Data Shape is: (3, 4) 1234after_reshape = ones_array.reshape(6,2)print(after_reshape)print(&quot;Data Shape is:&quot;, after_reshape.shape)# 배열의 형태를 변형해줄 수 있다. [[1 1] [1 1] [1 1] [1 1] [1 1] [1 1]] Data Shape is: (6, 2) 123after_reshape = ones_array.reshape(5,3)# cannot reshape array of size 12 into shape (5,3)# 이 뜻은 원래 배열의 값(12) 보다 더 크게 배열을 만들 수 없을을 뜻한다. --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-25-94cac763be50&gt; in &lt;module&gt;() ----&gt; 1 after_reshape = ones_array.reshape(5,3) ValueError: cannot reshape array of size 12 into shape (5,3) 1234after_reshape = ones_array.reshape(2,3,2)print(after_reshape)print(&quot;Data Shape is:&quot;, after_reshape.shape)# 2차원 3x4 배열을 3차원 2x3x2의 형태로 만들어 줄 수 있다. [[[1 1] [1 1] [1 1]] [[1 1] [1 1] [1 1]]] Data Shape is: (2, 3, 2) 1234after_reshape2= ones_array.reshape(-1,6)print(&quot;reshape(-1,6)? \\n&quot;)print(after_reshape2)# 배열을 바꿔줄때, 앞에 -1을 넣을 경우 자동으로 뒤의 숫자에 맞춰 리쉐이프를 진행해준다 reshape(-1,6)? [[1 1 1 1 1 1] [1 1 1 1 1 1]] Array 연산 Array연산은 기본적으로 크기가 서로 동일해야 진행된다. 이때 같은 위치에 있는 요소들 끼리 연산된다. 123arr1 = np.array([[1,2,3],[4,5,6]])arr1 array([[1, 2, 3], [4, 5, 6]]) 1234arr2 = np.array([[10,11,12],[13,14,15]])arr2 array([[10, 11, 12], [13, 14, 15]]) 1arr1 + arr2 array([[11, 13, 15], [17, 19, 21]]) 1arr1 - arr2 array([[-9, -9, -9], [-9, -9, -9]]) 12arr1 * arr2# 행렬의 곱셉처럼 진행되는게 아닌, 각 요소별로 곱셈이 진행된다. array([[10, 22, 36], [52, 70, 90]]) 1arr1 / arr2 array([[0.1 , 0.18181818, 0.25 ], [0.30769231, 0.35714286, 0.4 ]]) Array 브로드 캐스트 브로드캐스트란, 서로 크기가 다른 Array의 연산을 가능캐하는 것 이다. 12arr1 array([[1, 2, 3], [4, 5, 6]]) 12345arr3 = np.array([10,11,12])arr3 array([10, 11, 12]) 12arr1 + arr3# 이 결과처럼 arr1에 arr3이 각각 더해진다. array([[11, 13, 15], [14, 16, 18]]) 1arr1 * arr3 array([[10, 22, 36], [40, 55, 72]]) 그 외 연산1arr1 * 10 array([[10, 20, 30], [40, 50, 60]]) 12arr1 ** 2# 요소값에 제곱 array([[ 1, 4, 9], [16, 25, 36]]) Array boolean 인덱싱(마스크) Array의 다차원 인덱싱을 응용하여 boolean 인덱싱을 할 수 있다. 이러한 방법을 마스크라고 이야기한다 마스크처럼 원하는 요소만을 꺼낼 수 있다. 1234names = np.array(['A','B','C','D','E','F','G','H'])names array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'], dtype='&lt;U1') 123456data = np.random.randn(8,4)data#.random.randn 기대값 0 표준편차가 1인 난수를 발생시켜주는 함수다 array([[-0.78574336, 0.48987839, 0.82645617, -0.17152028], [-0.3937686 , -0.93822294, 2.14477087, 0.14940101], [ 1.43828557, 0.47514969, -0.08924484, -0.96863949], [ 0.38315778, 0.52111372, 0.05168264, -0.73003927], [ 1.22600484, -0.31477497, -0.70510052, -1.42081814], [-0.76256766, 0.61905043, -0.42352021, 1.8825546 ], [ 0.72534189, -2.13280186, 0.72306828, 1.18772154], [ 1.31611304, 0.98261818, 0.38594941, -0.25431404]]) names 와 data라는 두 array이가 있을때, 각 요소의 행이 연결되었고names가 A 인 행의 data를 본다고 하면 아래와 같이 해야한다. 1234# 요소가 A인 항목에 대한 mask 생성names_A_mask = (names == 'A')names_A_mask array([ True, False, False, False, False, False, False, False]) 1data[names_A_mask,:] array([[-0.78574336, 0.48987839, 0.82645617, -0.17152028]]) 위의 값을 본다면 0행의 값이 A인 것을 알 수 있다. 12data[names == 'B',:]# 요소가 B인 행의 데이터만 꺼내기 array([[-0.3937686 , -0.93822294, 2.14477087, 0.14940101]]) 123data[(names == 'C') | (names == 'D'),:]#논리값을 이용해 C 또는 D인 행의 데이터만 꺼내기 array([[ 1.43828557, 0.47514969, -0.08924484, -0.96863949], [ 0.38315778, 0.52111372, 0.05168264, -0.73003927]]) data array 자체적으로도 마스크를 만들고 응용이 가능하다.0번째 열이 0보다 작은 행을 구한다면 어떻게 해야할까? 12data[:,0] &lt; 0#먼저 data array에서 0번째 열이 0보다 작은 요소의 값은 다음과 같다. array([ True, True, False, False, False, True, False, False]) 12data[data[:,0]&lt;0,:]#위에서 만든 마스크를 이용해 0번째 열의 값이 0보다 작은 행을 구한다. array([[-0.78574336, 0.48987839, 0.82645617, -0.17152028], [-0.3937686 , -0.93822294, 2.14477087, 0.14940101], [-0.76256766, 0.61905043, -0.42352021, 1.8825546 ]]) 123data[data[:,0]&lt;0,2:4]#이걸 응용하면 특정위치에 값을 대입할 수 있다.#위의 코드는 0번째 열의 값이 0보다 작은 행의 2.3번째 열값이다. array([[ 0.82645617, -0.17152028], [ 2.14477087, 0.14940101], [-0.42352021, 1.8825546 ]]) 12345data[data[:,0]&lt;0,2:4] = 0data#이렇게 구한 열값에 0을 대입하면 아래와 같은 결과를 얻을 수 있다. array([[-0.78574336, 0.48987839, 0. , 0. ], [-0.3937686 , -0.93822294, 0. , 0. ], [ 1.43828557, 0.47514969, -0.08924484, -0.96863949], [ 0.38315778, 0.52111372, 0.05168264, -0.73003927], [ 1.22600484, -0.31477497, -0.70510052, -1.42081814], [-0.76256766, 0.61905043, 0. , 0. ], [ 0.72534189, -2.13280186, 0.72306828, 1.18772154], [ 1.31611304, 0.98261818, 0.38594941, -0.25431404]])","link":"/2021/11/02/numpy/"},{"title":"파이썬 시각화 1","text":"파이썬 시각화 .legend()(범례)는 그래프에 데이터의 종류를 표시하기위한 메서드다. 그래프 영역에 범례를 나타내기 위해선 먼저 plot() 함수에 label 문자열을 지정한다. 1234567891011121314151617181920# 파이썬 시각화를 위한 모듈세팅import matplotlib.pyplot as plt# 데이터 준비dates = [ '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', '2021-01-09', '2021-01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]# 하나의 ax 만을 가지는 하나의 figure 생성# figure 는 그래프를 그릴 공간을 의미하고 ax(axes)는 공간에 내가 사용할 부분을 의미한다.fig, ax = plt.subplots()# 그래프 그리기ax.plot(dates, min_temperature, label = &quot;Min Temp&quot;)ax.plot(dates, max_temperature, label = &quot;Max Temp&quot;)ax.legend()plt.show() 123456789101112131415import matplotlib.pyplot as pltdates = [ '2021-01-01', '2021-01-02', '2021-01-03', '2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', '2021-01-09', '2021-01-10']min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(10,6))# 위의 코드와 진행은 동일하지만, figure의 사이즈를 지정해준다.axes.plot(dates, min_temperature, label = 'Min Temperature')axes.plot(dates, max_temperature, label = 'Max Temperature')axes.legend()plt.show() 12print(fig)print(axes) Figure(720x432) AxesSubplot(0.125,0.125;0.775x0.755) Pyplot API + 객체지향 API Pyplot API : 이전절에 소개한 Matlab과 같이 커맨드 방식. matplotlib.pyplot 모듈에 함수로 정의되어 있음. 객체지향 API : matplotlib이 구현된 객체지향라이브러리를 직접 활용하는 방식. Pyplot API는 결국 객체지향 API로 편의함수를 구현한 것 뿐이기에 세밀한 제어를 위해서 객체지향 API를 사용해야한다. 12345678910import matplotlib.pyplot as pltimport numpy as npx = np.linspace(0,1,50)y1 = np.cos(4*np.pi*x)y2 = np.cos(4*np.pi*x)*np.exp(-2*x)fig,ax = plt.subplots(figsize=(10, 6)) # plt.subplots() 편의 함수는 Figure 객체를 생성하고 Figure.subplots()를 호출하여 리턴ax.plot(x,y1,'r-*',lw=1)ax.plot(x,y2,'b--',lw=1) [&lt;matplotlib.lines.Line2D at 0x7f83450f0690&gt;] 주가 데이터 패키지를 받아와 시각화 표현 예시 Yahoo Finance 사이트에서 주가데이터를 받아와본다. 먼저 !pip install yfinance 를 통해 패키지 설치 import fix_yahoo_finance as yf Yahoo 데이터를 yf에 임포트 해준다. import yfinance as yf yf에 임포트해준다. 12345678910111213141516!pip install yfinanceimport fix_yahoo_finance as yfimport yfinance as yfimport matplotlib.pyplot as pltdata = yf.download('AAPL', '2019-08-01', '2020-08-01')ts = data['Open']fig, ax = plt.subplots(figsize=(10, 6)) # 직접 Figure 객체 생성# ax= fig.subplots() # 직접 axes를 생성ax.plot(ts) # 생성된 axes 에 대한 plot() 멤버 직접 호출 ax.set_title('Stock Market fluctuation of AAPL')ax.legend(labels=['Price'], loc='best')ax.set_xlabel('Date')ax.set_ylabel('Stock Market Open Price')plt.show() Requirement already satisfied: yfinance in /usr/local/lib/python3.7/dist-packages (0.1.64) Requirement already satisfied: numpy&gt;=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5) Requirement already satisfied: multitasking&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9) Requirement already satisfied: lxml&gt;=4.5.1 in /usr/local/lib/python3.7/dist-packages (from yfinance) (4.6.4) Requirement already satisfied: pandas&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5) Requirement already satisfied: requests&gt;=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24-&gt;yfinance) (2.8.2) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.24-&gt;yfinance) (2018.9) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=0.24-&gt;yfinance) (1.15.0) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;yfinance) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;yfinance) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;yfinance) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.20-&gt;yfinance) (2021.5.30) [*********************100%***********************] 1 of 1 completed 막대 그래프 작성법 import calendar 을 통해 캘린더 데이터를 받아온다. for문을 통해 조건을 반복해 1~12월까지 반복해준다. 1234567891011121314151617181920import matplotlib.pyplot as pltimport numpy as npimport calendar # calendar 함수를 임포트 해준다.month_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]sold_list = [300, 400, 550, 900, 600, 960, 900, 910, 800, 700, 550, 450]fig, ax = plt.subplots(figsize=(10,6))plt.xticks(month_list, calendar.month_name[1:13], rotation=90)# .xticks() 는 x축에 눈금을 표시하는 함수입니다.# .yticks() 는 y축에 눈금을 표시해준다.plot = ax.bar(month_list, sold_list)for rect in plot: print(&quot;graph:&quot;, rect) height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.002*height,'%d' % int(height), ha='center', va='bottom')plt.show() graph: Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) graph: Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) graph: Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) graph: Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) graph: Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) graph: Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) graph: Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) graph: Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) graph: Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) graph: Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) 막대 그래프 해석 막대형 그래프는 범주 데이터를 요약하는 방법이다. 위의 그래프는 1월~12월까지의 개월을 calendar 함수를 통해 각 월별 이름을 받아와 월 별 데이터 범주 값을 나타내주고 있다. 산점도 그래프 작성법 import seaborn as sns 은 Matplotlib을 기반으로 다양한 색상 테마와 통계용 차트 등의 기능을 추가한 시각화 패키지이다. # sns.scatterplot(x='total_bill', y='tip', data=tips) 와 같이 각각 선언하지 않고 한번에 하는 것도 가능하다. 1234567891011121314151617import matplotlib.pyplot as pltimport seaborn as sns# 내장 데이터tips = sns.load_dataset(&quot;tips&quot;) # seaborn에서 제공하는 데이터를 불러온다.x = tips['total_bill']y = tips['tip']# sns.scatterplot(x='total_bill', y='tip', data=tips)fig, ax = plt.subplots(figsize=(10, 6))ax.scatter(x, y) # x축과 y축을 그래프에 지정ax.set_xlabel('Total Bill') # x축 변수명 선언ax.set_ylabel('Tip') # y축 변수명 선언ax.set_title('Tip ~ Total Bill') # 그래프 타이틀 선언fig.show() 산점도 그룹화 그래프 작성법 label, data = tips.groupby('sex') 위 코드를 통해 tips의 데이터를 sex로 그룹화를 진행해준다. 1label, data = tips.groupby('sex') 1234567891011121314151617181920212223import matplotlib.pyplot as pltimport seaborn as snstips['sex_color'] = tips['sex'].map({&quot;Female&quot; : &quot;#0000FF&quot;, &quot;Male&quot; : &quot;#00FF00&quot;})# 남성과 여성의 변수명과 색상을 설정해준다.fig, ax = plt.subplots(figsize=(10, 6))for label, data in tips.groupby('sex'): # 그룹화한 변수를 불러와 준다. ax.scatter(data['total_bill'], data['tip'], label=label, color=data['sex_color'], alpha=0.5) # scatter를 이용해 점을 찍어준다. # alpha=n 은 점의 크기 ax.set_xlabel('Total Bill') ax.set_ylabel('Tip') ax.set_title('Tip ~ Total Bill by Gender')ax.legend()fig.show() 산점도 그래프 해석 두 변수 간의 영향력을 보여주기 위해 가로 축과 세로 축에 데이터 포인트를 그리는 데 사용된다. 산점도는 두 변수간의 상관 관계를 나타내주는데, 점이 산점도에서 직선에 가까운 경우 두 변수의 상관관계가 높다고 본다. 점이 균등하게 분산되어 있는 경우 상관관계가 낮거나 0에 가깝다. 두 변수가 다른 변수와 모두 연관될 수 있다. 즉, 우연한 일치로 인해 상관관계가 생성될 수 있다. 그러므로 상관관계만으로 인과관계를 장담할 수 없다. 산점도는 분석을 할 때 참조선이나 곡선 유형을추가하여 일반적으로 사용된다. 히스토그램 그래프 작성법 seaborn 에 저장된 titanic 데이터 프레임의 age 데이터만을 가져온다. 1234567891011121314151617181920212223import matplotlib.pyplot as pltimport numpy as npimport seaborn as sns# 내장 데이터 titanic = sns.load_dataset('titanic')age = titanic['age']bins = 21# 가로축 구간 갯수 지정#nbins = 21 로 작성해도 상관없다.fig, ax = plt.subplots(figsize=(10, 6))ax.hist(age, bins = bins)# 히스토그램의 가로축을 지정해주는 함수 .hist()ax.set_xlabel(&quot;Age&quot;)ax.set_ylabel(&quot;Frequency&quot;)ax.set_title(&quot;Distribution of Age in Titanic&quot;)ax.axvline(x = age.mean(), linewidth = 2, color = 'r')# 히스토그램의 평균값을 선으로 나타내주는 함수 .axvline()fig.show() 히스토그램 그래프 해석 히스토그램은 한개의 변수의 구간별 빈도를 나태난다. 위의 표는 age 구간별로 탑승객들의 빈도수를 나타내준다. 박스플롯 그래프 작성법12345678910111213import matplotlib.pyplot as pltimport seaborn as snsiris = sns.load_dataset('iris')data = [iris[iris['species']==&quot;setosa&quot;]['petal_width'], iris[iris['species']==&quot;versicolor&quot;]['petal_width'], iris[iris['species']==&quot;virginica&quot;]['petal_width']]fig, ax = plt.subplots(figsize=(10, 6))ax.boxplot(data, labels=['setosa', 'versicolor', 'virginica'])fig.show() 박스플롯 그래프 해석 박스플롯은 데이터의 집합의 범위와 중앙값을 빠르게 확인 할 수 있다. 또, 통계적 이상치 또한 나타내준다. 위의 그래프의 경우 iris(꽃) 데이터의 species(종) 데이터 부분에서 3가지 품종(setosa,versicolor, virginica) 데이터의 수치를 표현한다. 그래프의 각각 의미는 최댓값 제 1사분위(Q1) 중앙값(제 2사분위(Q2)) 제 3사분위(Q3) 최솟값 최솟값과 최댓값을 넘어가는 위치의 값은 이상치라 부른다. 히트맵 matplotlib 모듈에는 히트맵을 바로 사용할 수 있는 함수가 존재하지 않는다. 그럼으로 get_cmap() 를 통해 바로 가져오지 않고 imshow() 함수를 활용하여 가져온다. 1234567891011121314151617import matplotlib.pyplot as pltimport numpy as npimport seaborn as sns# 내장 데이터flights = sns.load_dataset(&quot;flights&quot;)flights = flights.pivot(&quot;month&quot;, &quot;year&quot;, &quot;passengers&quot;)fig, ax = plt.subplots(figsize=(12, 6))im = ax.imshow(flights, cmap = 'YlGnBu')# 히트맵의 색상을 지정해준다.ax.set_xticklabels(flights.columns, rotation = 20)ax.set_yticklabels(flights.index, rotation = 10)fig.colorbar(im)# 그래프 우측에 구간별 컬러바를 나타내는 함수fig.show() 히트맵 그래프 해석 히트맵은 다양한 값을 갖는 숫자 데이터를 열분포 형태와 같이 색상을 이용해 직관적으로 나타낸 그래프다. x축과 y축을 범주형 변수로 하고 각 칸에 수치형 변수를 채운다. 구체적인 수치가 없어도 많은 데이터의 패턴을 나타내는데 주로 사용된다. 위의 데이터의 경우 1950 ~ 1955년 사이 2~7월 사이의 비행기 탑승객의 수를 나타내준다. Seaborn Seaborn 라이브러를 활용해서 다양한 통계 그래프를 그릴 수 있다. 산점도, 회귀선이 있는 선점도 작성법 -%matplotlib inline 는 출력옵션의 한 종류로, 이미지, 사운드, 애니메이션 등으로 표현되는 객체를 Jupyter등의 프론트에서 표시되게 하는 기능을 한다. 123456789%matplotlib inline import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)sns.scatterplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips)plt.show() 12345678910111213141516fig, ax = plt.subplots(nrows = 1, ncols = 2, figsize=(15, 5))# nrows = 행, ncols = 열sns.regplot(x = &quot;total_bill&quot;, #x축 지정 y = &quot;tip&quot;, #y축 지정 data = tips, ax = ax[0], # 그래프 구분 넘버링 fit_reg = True) # 회귀선 표시 유무sns.regplot(x = &quot;total_bill&quot;, y = &quot;tip&quot;, data = tips, ax = ax[1], fit_reg = False)plt.show() 산점도, 회귀선 그래프 해석 norws는 출력의 행의 갯수, ncols는 열의 갯수를 의미한다. ax = ax[]의 윗줄에 지정한 범위만큼의 값을 넣으면 각 그래프별로 다른 데이터를 넣을 수 있다. regplot() 함수를 이용해 회귀선을 나타냈다. regplot() 함수 안에 있는 fit_reg 를 True로 할 경우 회귀선이 나타나고, False로 하면 회귀선이 나오지 않는다. 히스토그램/커널 밀도 그래프12345678import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)sns.displot(x = &quot;tip&quot;, data = tips)plt.figure(figsize=(10, 6))plt.show() &lt;Figure size 720x432 with 0 Axes&gt; 123sns.displot(x=&quot;tip&quot;, kind=&quot;kde&quot;, data=tips)plt.show()# 커널 밀도 그래프 추가 123sns.displot(x=&quot;tip&quot;, kde=True, data=tips)plt.show()# 위의 두 그래프를 합쳐준다. 박스플롯123sns.boxplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data = tips)sns.swarmplot(x = &quot;day&quot;, y = &quot;total_bill&quot;, data = tips, alpha = .25)plt.show() 막대 그래프12sns.countplot(x = &quot;day&quot;, data = tips)plt.show() 123456ax = sns.countplot(x = &quot;day&quot;, data = tips, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show() 12345678ax = sns.countplot(x = &quot;day&quot;, data = tips, hue = &quot;sex&quot;, dodge = True, order = tips['day'].value_counts().index)for p in ax.patches: height = p.get_height() ax.text(p.get_x() + p.get_width()/2., height+3, height, ha = 'center', size=9)ax.set_ylim(-5, 100)plt.show()","link":"/2021/11/03/data-visualization/"},{"title":"Decision Tree","text":"머신러닝 모델Decision Tree Decison Tree(결정트리) 는 분류, 회귀 모두 가능한 지도 학습 모델 중 하나다. 결정 트리는 특정 기준(질문)에 따라 데이터를 구분하는 모델이다. 이러한 방식으로 데이터를 분류하는 것은 스무고개와 유사한 방식으로 이루어진다. 결정트리 알고리즘 용어 Node(노드) : 결정트리에서 질문이나 정답을 담은 네모 상자(분기점) Root Ndoe(루트노드) : 깊이가 0인 가장 위의 노드 Leaf Node(리프노드) : 자식 노드가 없는 마지막 노드 진행과정 첫번째로 root node(꼭대기)에서 시작한다. 다리가 있나요? 라는 질문을 검사한다(조건에 따라 좌우 분기) 만약 ‘아니’ 라면 오른쪽으로 이동해 root node에서 했던 조건의 검사를 실시하여 반복한다. 마지막에 leaf node(끝) 에 도달했을 때, 추가적인 조건 검사 없이 가장 많은 클래스의 비중을 차지하고 있는 곳으로 클래스를 예측하게된다.(토끼,강아지)(고래,소라고동) 결정 트리의 장점은 스케일이나 평균으 원점에 맞추는 것같은 데이터 전처리가 거의 필요하지 않다. 또 매우 직관적이고 이해하기 쉬우며 동시에 해석력이 좋다. 반대로 방식이 매우 단순하기 때문에 이를 극복하기 위해 랜덤 포레스트(Random Forest)를 사용할 수 있다. 그러나 새로운 데이터가 반영될 때 마다 숲(Forest)를 다시 만들어줘야 하기 때문에 풀고자하는 문제에 비해 계산량이 많아진다는 단점이 있다. Decision Tree 예제 결정트리를 이해하기 쉽게 Sklearn에서 제공하는 데이터셋을 이용한 예제다. 1234567891011121314151617181920212223from sklearn.tree import DecisionTreeClassifier# 싸이킷런 데이터를 의사결정 트리를 임포트 해준다.from sklearn.datasets import load_breast_cancer# 싸이킷런에서 제공하는 유방암 데이터를 가져온다.from sklearn.model_selection import train_test_split# 분석에 이용할 train, test 함수를 선언해준다.cancer = load_breast_cancer()# 샘플 데이터(유방암 데이터)를 로드해준다.X_train, X_test, y_train, y_test = train_test_split( cancer.data, cancer.target, stratify=cancer.target, random_state=42)# 훈련, 테스트 데이터를 셔플해준다.treeAll = DecisionTreeClassifier(random_state=0)# 의사결정 트리 선언treeAll.fit(X_train, y_train)# 훈련 시작(모든 리프 노드를 사용한다)print(&quot;훈련 세트 정확도: {:.3f}&quot;.format(tree.score(X_train, y_train)))print(&quot;테스트 세트 정확도: {:.3f}&quot;.format(tree.score(X_test, y_test)))#점수를 출력한다. 훈련 세트 정확도: 0.988 테스트 세트 정확도: 0.951 1234567891011treeLimit = DecisionTreeClassifier(max_depth=4, random_state=0)#의사결정 트리 선언, 이때 트리 깊이(분기)를 제한해준다.treeLimit.fit(X_train, y_train)#훈련시작, 이때 리프노드의 깊이를 제한한다.print(&quot;훈련 세트 정확도: {:.3f}&quot;.format(tree.score(X_train, y_train)))print(&quot;테스트 세트 정확도: {:.3f}&quot;.format(tree.score(X_test, y_test)))#점수를 출력한다. 훈련 세트 정확도: 0.988 테스트 세트 정확도: 0.951 결정 트리 모듈 시각화 및 분석 export_graphviz 함수를 이용해 트리를 시각화 export_graphviz 함수에 filled 매개변수를 True로 지정하면 노드의 클래스가 구분되도록 색으로 칠해진다. 클래스 이름과 특성 이름을 매개변수로 전달 1234from sklearn.tree import export_graphvizexport_graphviz(tree, out_file=&quot;tree.dot&quot;, class_names=[&quot;악성&quot;, &quot;양성&quot;], feature_names=cancer.feature_names, impurity=False, filled=True) graphviz 모듈을 사용해 시각화한다. 12345import graphvizwith open(&quot;tree.dot&quot;) as f: dot_graph = f.read()display(graphviz.Source(dot_graph)) 참고자료 머신러닝 - 4. 결정 트리 텐서 플로우 블로그 - 2.3.4 결정트리 유튜브 허민석 - 의사결정트리 알고리즘 쉽게 이해하기 svg 파일 png 변환","link":"/2021/11/04/Decision-Tree/"},{"title":"Kaggle_house_price","text":"캐글캐글 : 주택가격 데이터 분석캐글 데이터셋을 불러온다1!pip install kaggle Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) 내가 참여한 대회의 .json 파일을 colab에 임포트 해준다.12345678910from google.colab import filesuploaded = files.upload()for fn in uploaded.keys(): print('User uploaded file &quot;{name}&quot; with length {length} bytes'.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it.!mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &quot;kaggle.json&quot; with length 64 bytes 대회에 사용되는 데이터를 다운로드 및 불러오기1!kaggle competitions list Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) ref deadline category reward teamCount userHasEntered --------------------------------------------- ------------------- --------------- --------- --------- -------------- contradictory-my-dear-watson 2030-07-01 23:59:00 Getting Started Prizes 63 False gan-getting-started 2030-07-01 23:59:00 Getting Started Prizes 81 False store-sales-time-series-forecasting 2030-06-30 23:59:00 Getting Started Knowledge 487 False tpu-getting-started 2030-06-03 23:59:00 Getting Started Knowledge 158 False digit-recognizer 2030-01-01 00:00:00 Getting Started Knowledge 1456 False titanic 2030-01-01 00:00:00 Getting Started Knowledge 14873 False house-prices-advanced-regression-techniques 2030-01-01 00:00:00 Getting Started Knowledge 4418 True connectx 2030-01-01 00:00:00 Getting Started Knowledge 262 False nlp-getting-started 2030-01-01 00:00:00 Getting Started Knowledge 1321 False competitive-data-science-predict-future-sales 2022-12-31 23:59:00 Playground Kudos 12891 False g-research-crypto-forecasting 2022-02-01 23:59:00 Featured $125,000 144 False petfinder-pawpularity-score 2022-01-13 23:59:00 Research $25,000 1630 False optiver-realized-volatility-prediction 2022-01-10 23:59:00 Featured $100,000 3852 False nfl-big-data-bowl-2022 2022-01-06 23:59:00 Analytics $100,000 0 False sartorius-cell-instance-segmentation 2021-12-30 23:59:00 Featured $75,000 495 False wikipedia-image-caption 2021-12-09 11:59:00 Playground Swag 71 False lux-ai-2021 2021-12-06 23:59:00 Featured $10,000 927 False tabular-playground-series-nov-2021 2021-11-30 23:59:00 Playground Swag 352 False kaggle-survey-2021 2021-11-28 23:59:00 Analytics $30,000 0 True chaii-hindi-and-tamil-question-answering 2021-11-15 23:59:00 Research $10,000 807 False 1!kaggle competitions download -c house-prices-advanced-regression-techniques Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) Downloading test.csv to /content 0% 0.00/441k [00:00&lt;?, ?B/s] 100% 441k/441k [00:00&lt;00:00, 60.6MB/s] Downloading sample_submission.csv to /content 0% 0.00/31.2k [00:00&lt;?, ?B/s] 100% 31.2k/31.2k [00:00&lt;00:00, 28.2MB/s] Downloading data_description.txt to /content 0% 0.00/13.1k [00:00&lt;?, ?B/s] 100% 13.1k/13.1k [00:00&lt;00:00, 23.2MB/s] Downloading train.csv to /content 0% 0.00/450k [00:00&lt;?, ?B/s] 100% 450k/450k [00:00&lt;00:00, 64.1MB/s] 1234import pandas as pd train = pd.read_csv('train.csv')test = pd.read_csv('test.csv')print('Data Loading is done!') Data Loading is done! 데이터 둘러보기123print(&quot;The shape of Train Data is:&quot;, train.shape)print(&quot;The shape of Test Data is:&quot;, test.shape)# 각 데이터의 행렬값을 출력해준다. The shape of Train Data is: (1460, 81) The shape of Test Data is: (1459, 80) 1print(train.info()) &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 81 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Id 1460 non-null int64 1 MSSubClass 1460 non-null int64 2 MSZoning 1460 non-null object 3 LotFrontage 1201 non-null float64 4 LotArea 1460 non-null int64 5 Street 1460 non-null object 6 Alley 91 non-null object 7 LotShape 1460 non-null object 8 LandContour 1460 non-null object 9 Utilities 1460 non-null object 10 LotConfig 1460 non-null object 11 LandSlope 1460 non-null object 12 Neighborhood 1460 non-null object 13 Condition1 1460 non-null object 14 Condition2 1460 non-null object 15 BldgType 1460 non-null object 16 HouseStyle 1460 non-null object 17 OverallQual 1460 non-null int64 18 OverallCond 1460 non-null int64 19 YearBuilt 1460 non-null int64 20 YearRemodAdd 1460 non-null int64 21 RoofStyle 1460 non-null object 22 RoofMatl 1460 non-null object 23 Exterior1st 1460 non-null object 24 Exterior2nd 1460 non-null object 25 MasVnrType 1452 non-null object 26 MasVnrArea 1452 non-null float64 27 ExterQual 1460 non-null object 28 ExterCond 1460 non-null object 29 Foundation 1460 non-null object 30 BsmtQual 1423 non-null object 31 BsmtCond 1423 non-null object 32 BsmtExposure 1422 non-null object 33 BsmtFinType1 1423 non-null object 34 BsmtFinSF1 1460 non-null int64 35 BsmtFinType2 1422 non-null object 36 BsmtFinSF2 1460 non-null int64 37 BsmtUnfSF 1460 non-null int64 38 TotalBsmtSF 1460 non-null int64 39 Heating 1460 non-null object 40 HeatingQC 1460 non-null object 41 CentralAir 1460 non-null object 42 Electrical 1459 non-null object 43 1stFlrSF 1460 non-null int64 44 2ndFlrSF 1460 non-null int64 45 LowQualFinSF 1460 non-null int64 46 GrLivArea 1460 non-null int64 47 BsmtFullBath 1460 non-null int64 48 BsmtHalfBath 1460 non-null int64 49 FullBath 1460 non-null int64 50 HalfBath 1460 non-null int64 51 BedroomAbvGr 1460 non-null int64 52 KitchenAbvGr 1460 non-null int64 53 KitchenQual 1460 non-null object 54 TotRmsAbvGrd 1460 non-null int64 55 Functional 1460 non-null object 56 Fireplaces 1460 non-null int64 57 FireplaceQu 770 non-null object 58 GarageType 1379 non-null object 59 GarageYrBlt 1379 non-null float64 60 GarageFinish 1379 non-null object 61 GarageCars 1460 non-null int64 62 GarageArea 1460 non-null int64 63 GarageQual 1379 non-null object 64 GarageCond 1379 non-null object 65 PavedDrive 1460 non-null object 66 WoodDeckSF 1460 non-null int64 67 OpenPorchSF 1460 non-null int64 68 EnclosedPorch 1460 non-null int64 69 3SsnPorch 1460 non-null int64 70 ScreenPorch 1460 non-null int64 71 PoolArea 1460 non-null int64 72 PoolQC 7 non-null object 73 Fence 281 non-null object 74 MiscFeature 54 non-null object 75 MiscVal 1460 non-null int64 76 MoSold 1460 non-null int64 77 YrSold 1460 non-null int64 78 SaleType 1460 non-null object 79 SaleCondition 1460 non-null object 80 SalePrice 1460 non-null int64 dtypes: float64(3), int64(35), object(43) memory usage: 924.0+ KB None 1print(test.info()) &lt;class 'pandas.core.frame.DataFrame'&gt; RangeIndex: 1459 entries, 0 to 1458 Data columns (total 80 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Id 1459 non-null int64 1 MSSubClass 1459 non-null int64 2 MSZoning 1455 non-null object 3 LotFrontage 1232 non-null float64 4 LotArea 1459 non-null int64 5 Street 1459 non-null object 6 Alley 107 non-null object 7 LotShape 1459 non-null object 8 LandContour 1459 non-null object 9 Utilities 1457 non-null object 10 LotConfig 1459 non-null object 11 LandSlope 1459 non-null object 12 Neighborhood 1459 non-null object 13 Condition1 1459 non-null object 14 Condition2 1459 non-null object 15 BldgType 1459 non-null object 16 HouseStyle 1459 non-null object 17 OverallQual 1459 non-null int64 18 OverallCond 1459 non-null int64 19 YearBuilt 1459 non-null int64 20 YearRemodAdd 1459 non-null int64 21 RoofStyle 1459 non-null object 22 RoofMatl 1459 non-null object 23 Exterior1st 1458 non-null object 24 Exterior2nd 1458 non-null object 25 MasVnrType 1443 non-null object 26 MasVnrArea 1444 non-null float64 27 ExterQual 1459 non-null object 28 ExterCond 1459 non-null object 29 Foundation 1459 non-null object 30 BsmtQual 1415 non-null object 31 BsmtCond 1414 non-null object 32 BsmtExposure 1415 non-null object 33 BsmtFinType1 1417 non-null object 34 BsmtFinSF1 1458 non-null float64 35 BsmtFinType2 1417 non-null object 36 BsmtFinSF2 1458 non-null float64 37 BsmtUnfSF 1458 non-null float64 38 TotalBsmtSF 1458 non-null float64 39 Heating 1459 non-null object 40 HeatingQC 1459 non-null object 41 CentralAir 1459 non-null object 42 Electrical 1459 non-null object 43 1stFlrSF 1459 non-null int64 44 2ndFlrSF 1459 non-null int64 45 LowQualFinSF 1459 non-null int64 46 GrLivArea 1459 non-null int64 47 BsmtFullBath 1457 non-null float64 48 BsmtHalfBath 1457 non-null float64 49 FullBath 1459 non-null int64 50 HalfBath 1459 non-null int64 51 BedroomAbvGr 1459 non-null int64 52 KitchenAbvGr 1459 non-null int64 53 KitchenQual 1458 non-null object 54 TotRmsAbvGrd 1459 non-null int64 55 Functional 1457 non-null object 56 Fireplaces 1459 non-null int64 57 FireplaceQu 729 non-null object 58 GarageType 1383 non-null object 59 GarageYrBlt 1381 non-null float64 60 GarageFinish 1381 non-null object 61 GarageCars 1458 non-null float64 62 GarageArea 1458 non-null float64 63 GarageQual 1381 non-null object 64 GarageCond 1381 non-null object 65 PavedDrive 1459 non-null object 66 WoodDeckSF 1459 non-null int64 67 OpenPorchSF 1459 non-null int64 68 EnclosedPorch 1459 non-null int64 69 3SsnPorch 1459 non-null int64 70 ScreenPorch 1459 non-null int64 71 PoolArea 1459 non-null int64 72 PoolQC 3 non-null object 73 Fence 290 non-null object 74 MiscFeature 51 non-null object 75 MiscVal 1459 non-null int64 76 MoSold 1459 non-null int64 77 YrSold 1459 non-null int64 78 SaleType 1458 non-null object 79 SaleCondition 1459 non-null object dtypes: float64(11), int64(26), object(43) memory usage: 912.0+ KB None Feature Engineering이상치를 제거한다.1234train.drop(train[(train['OverallQual']&lt;4) &amp; (train['SalePrice']&gt; 200000)].index, inplace=True)train.drop(train[(train['OverallCond']&lt;4) &amp; (train['SalePrice']&gt; 200000)].index, inplace=True)train.reset_index(drop=True, inplace=True)print(train.shape) (1458, 81) 종속변수의 로그 변환 히스토그램으로 시각화 123456789101112131415161718import seaborn as snsimport matplotlib.pyplot as pltfrom scipy.stats import norm(mu, sigma) = norm.fit(train['SalePrice'])print(&quot;The value of mu before log transformation is:&quot;, mu)print(&quot;The value of sigma before log transformation is:&quot;, sigma)fig, ax = plt.subplots(figsize=(10, 6))sns.histplot(train['SalePrice'], color=&quot;b&quot;, stat=&quot;probability&quot;)ax.xaxis.grid(False)ax.set(ylabel=&quot;Frequency&quot;)ax.set(xlabel=&quot;SalePrice&quot;)ax.set(title=&quot;SalePrice distribution&quot;)plt.axvline(mu, color='r', linestyle='--')plt.text(mu + 10000, 0.11, 'Mean of SalePrice', rotation=0, color='r')fig.show() The value of mu before log transformation is: 180761.24142661178 The value of sigma before log transformation is: 79270.93617295024 ! 종속변수(주택가격)이 한쪽으로 치우쳐 있기 때문에 예측 성능 상승을 위해 로그를 변환시켜준다. 12345678910111213141516171819import numpy as np train[&quot;SalePrice&quot;] = np.log1p(train[&quot;SalePrice&quot;])(mu, sigma) = norm.fit(train['SalePrice'])print(&quot;The value of mu before log transformation is:&quot;, mu)print(&quot;The value of sigma before log transformation is:&quot;, sigma)fig, ax = plt.subplots(figsize=(10, 6))sns.histplot(train['SalePrice'], color=&quot;b&quot;, stat=&quot;probability&quot;)ax.xaxis.grid(False)ax.set(ylabel=&quot;Frequency&quot;)ax.set(xlabel=&quot;SalePrice&quot;)ax.set(title=&quot;SalePrice distribution&quot;)plt.axvline(mu, color='r', linestyle='--')plt.text(mu + 0.05, 0.111, 'Mean of SalePrice', rotation=0, color='r')plt.ylim(0, 0.12)fig.show() The value of mu before log transformation is: 12.0233397799989 The value of sigma before log transformation is: 0.3989191793099824 ! 데이터 ID 값 제거 로그를 변환해주고나서 데이터(종속변수)가 변환된걸 볼 수 있다 분석을 위해 사용되지 않을 변수를 추출해준다. 12345train_ID = train['Id']test_ID = test['Id']train.drop(['Id'], axis=1, inplace=True)test.drop(['Id'], axis=1, inplace=True)train.shape, test.shape ((1458, 80), (1459, 79)) Y값을 추출한다.123y = train['SalePrice'].reset_index(drop=True)train = train.drop('SalePrice', axis = 1)train.shape, test.shape, y.shape ((1458, 79), (1459, 79), (1458,)) 데이터 합치기12all_df = pd.concat([train, test]).reset_index(drop=True)all_df.shape (2917, 79) 데이터 결측치 확인12345678def check_na(data, head_num = 6): isnull_na = (data.isnull().sum() / len(data)) * 100 data_na = isnull_na.drop(isnull_na[isnull_na == 0].index).sort_values(ascending=False) missing_data = pd.DataFrame({'Missing Ratio' :data_na, 'Data Type': data.dtypes[data_na.index]}) print(&quot;결측치 데이터 컬럼과 건수:\\n&quot;, missing_data.head(head_num))check_na(all_df, 20) 결측치 데이터 컬럼과 건수: Missing Ratio Data Type PoolQC 99.657182 object MiscFeature 96.400411 object Alley 93.212204 object Fence 80.425094 object FireplaceQu 48.680151 object LotFrontage 16.626671 float64 GarageFinish 5.450806 object GarageYrBlt 5.450806 float64 GarageQual 5.450806 object GarageCond 5.450806 object GarageType 5.382242 object BsmtExposure 2.811107 object BsmtCond 2.811107 object BsmtQual 2.776826 object BsmtFinType2 2.742544 object BsmtFinType1 2.708262 object MasVnrType 0.788481 object MasVnrArea 0.754200 float64 MSZoning 0.137127 object BsmtFullBath 0.068564 float64 결측치 제거12all_df.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage'], axis=1, inplace=True)check_na(all_df) 결측치 데이터 컬럼과 건수: Missing Ratio Data Type GarageQual 5.450806 object GarageFinish 5.450806 object GarageYrBlt 5.450806 float64 GarageCond 5.450806 object GarageType 5.382242 object BsmtCond 2.811107 object 결측치 채우기123print(all_df['BsmtCond'].value_counts())print()print(all_df['BsmtCond'].mode()[0]) TA 2604 Gd 122 Fa 104 Po 5 Name: BsmtCond, dtype: int64 TA 1234567891011121314import numpy as npcat_all_vars = train.select_dtypes(exclude=[np.number])print(&quot;The whole number of all_vars&quot;, len(list(cat_all_vars)))final_cat_vars = []for v in cat_all_vars: if v not in ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'LotFrontage']: final_cat_vars.append(v)print(&quot;The whole number of final_cat_vars&quot;, len(final_cat_vars))for i in final_cat_vars: all_df[i] = all_df[i].fillna(all_df[i].mode()[0])check_na(all_df, 20) The whole number of all_vars 43 The whole number of final_cat_vars 38 결측치 데이터 컬럼과 건수: Missing Ratio Data Type GarageYrBlt 5.450806 float64 MasVnrArea 0.754200 float64 BsmtHalfBath 0.068564 float64 BsmtFullBath 0.068564 float64 GarageArea 0.034282 float64 GarageCars 0.034282 float64 TotalBsmtSF 0.034282 float64 BsmtUnfSF 0.034282 float64 BsmtFinSF2 0.034282 float64 BsmtFinSF1 0.034282 float64 1234567891011import numpy as npnum_all_vars = list(train.select_dtypes(include=[np.number]))print(&quot;The whole number of all_vars&quot;, len(num_all_vars))num_all_vars.remove('LotFrontage')print(&quot;The whole number of final_cat_vars&quot;, len(num_all_vars))for i in num_all_vars: all_df[i].fillna(value=all_df[i].median(), inplace=True)check_na(all_df, 20) The whole number of all_vars 36 The whole number of final_cat_vars 35 결측치 데이터 컬럼과 건수: Empty DataFrame Columns: [Missing Ratio, Data Type] Index: [] 왜도(Skewnewss) 처리하기 왜도 데이터 확인 1234567from scipy.stats import skewdef find_skew(x): return skew(x)skewness_features = all_df[num_all_vars].apply(find_skew).sort_values(ascending=False)skewness_features MiscVal 21.939672 PoolArea 16.892477 LotArea 12.867139 LowQualFinSF 12.084539 3SsnPorch 11.372080 KitchenAbvGr 4.318923 BsmtFinSF2 4.144503 EnclosedPorch 4.013741 ScreenPorch 3.945101 BsmtHalfBath 3.929996 MasVnrArea 2.615714 OpenPorchSF 2.534326 WoodDeckSF 1.841876 1stFlrSF 1.469798 BsmtFinSF1 1.429239 MSSubClass 1.374726 GrLivArea 1.271773 TotalBsmtSF 1.165468 BsmtUnfSF 0.919795 2ndFlrSF 0.860643 TotRmsAbvGrd 0.760404 Fireplaces 0.734449 HalfBath 0.695072 BsmtFullBath 0.626733 OverallCond 0.584601 BedroomAbvGr 0.329555 GarageArea 0.241611 OverallQual 0.196514 MoSold 0.195229 FullBath 0.164226 YrSold 0.132129 GarageCars -0.218309 GarageYrBlt -0.398311 YearRemodAdd -0.451063 YearBuilt -0.600023 dtype: float64 박스플롯 형태로 시각화 123456789101112skewnewss_index = list(skewness_features.index)skewnewss_index.remove('LotArea')all_numeric_df = all_df.loc[:, skewnewss_index]fig, ax = plt.subplots(figsize=(10, 6))ax.set_xlim(0, all_numeric_df.max().sort_values(ascending=False)[0])ax = sns.boxplot(data=all_numeric_df[skewnewss_index] , orient=&quot;h&quot;, palette=&quot;Set1&quot;)ax.xaxis.grid(False)ax.set(ylabel=&quot;Feature names&quot;)ax.set(xlabel=&quot;Numeric values&quot;)ax.set(title=&quot;Numeric Distribution of Features Before Box-Cox Transformation&quot;)sns.despine(trim=True, left=True) ! 왜도 데이터 삭제 123456789101112from scipy.special import boxcox1pfrom scipy.stats import boxcox_normmaxhigh_skew = skewness_features[skewness_features &gt; 1]high_skew_index = high_skew.indexprint(&quot;The data before Box-Cox Transformation: \\n&quot;, all_df[high_skew_index].head())for num_var in high_skew_index: all_df[num_var] = boxcox1p(all_df[num_var], boxcox_normmax(all_df[num_var] + 1))print(&quot;The data after Box-Cox Transformation: \\n&quot;, all_df[high_skew_index].head()) The data before Box-Cox Transformation: MiscVal PoolArea LotArea ... MSSubClass GrLivArea TotalBsmtSF 0 0 0 8450 ... 60 1710 856.0 1 0 0 9600 ... 20 1262 1262.0 2 0 0 11250 ... 60 1786 920.0 3 0 0 9550 ... 70 1717 756.0 4 0 0 14260 ... 60 2198 1145.0 [5 rows x 18 columns] The data after Box-Cox Transformation: MiscVal PoolArea LotArea ... MSSubClass GrLivArea TotalBsmtSF 0 0.0 0.0 13.454344 ... 6.505897 7.219262 294.614887 1 0.0 0.0 13.725427 ... 4.252612 6.933523 404.051498 2 0.0 0.0 14.066408 ... 6.505897 7.260108 312.423510 3 0.0 0.0 13.714276 ... 6.869385 7.223100 266.274241 4 0.0 0.0 14.584552 ... 6.505897 7.454890 373.304502 [5 rows x 18 columns] /usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined. warnings.warn(PearsonRConstantInputWarning()) /usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3538: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate. warnings.warn(PearsonRNearConstantInputWarning()) 12345678fig, ax = plt.subplots(figsize=(10, 6))ax.set_xscale('log')ax = sns.boxplot(data=all_df[high_skew_index] , orient=&quot;h&quot;, palette=&quot;Set1&quot;)ax.xaxis.grid(False)ax.set(ylabel=&quot;Feature names&quot;)ax.set(xlabel=&quot;Numeric values&quot;)ax.set(title=&quot;Numeric Distribution of Features Before Box-Cox Transformation&quot;)sns.despine(trim=True, left=True) ! 도출변수 집의 크기에 해당하는 변수를 묶어서 처리해준다. 123all_df['TotalSF'] = all_df['TotalBsmtSF'] + all_df['1stFlrSF'] + all_df['2ndFlrSF']all_df = all_df.drop(['TotalBsmtSF', '1stFlrSF', '2ndFlrSF'], axis=1)print(all_df.shape) 집의 욕조, 풀장과 같은 옵션을 하나로 묶는다. 1234all_df['Total_Bathrooms'] = (all_df['FullBath'] + (0.5 * all_df['HalfBath']) + all_df['BsmtFullBath'] + (0.5 * all_df['BsmtHalfBath']))all_df['Total_porch_sf'] = (all_df['OpenPorchSF'] + all_df['3SsnPorch'] + all_df['EnclosedPorch'] + all_df['ScreenPorch'])all_df = all_df.drop(['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath', 'OpenPorchSF', '3SsnPorch', 'EnclosedPorch', 'ScreenPorch'], axis=1)print(all_df.shape) 집의 준공연도, 리모델링연도, 판매연도, 등 기간에 관한 변수를 하나로 묶는다. 12345678910num_all_vars = list(train.select_dtypes(include=[np.number]))year_feature = []for var in num_all_vars: if 'Yr' in var: year_feature.append(var) elif 'Year' in var: year_feature.append(var) else: print(var, &quot;is not related with Year&quot;)print(year_feature) MSSubClass is not related with Year LotFrontage is not related with Year LotArea is not related with Year OverallQual is not related with Year OverallCond is not related with Year MasVnrArea is not related with Year BsmtFinSF1 is not related with Year BsmtFinSF2 is not related with Year BsmtUnfSF is not related with Year TotalBsmtSF is not related with Year 1stFlrSF is not related with Year 2ndFlrSF is not related with Year LowQualFinSF is not related with Year GrLivArea is not related with Year BsmtFullBath is not related with Year BsmtHalfBath is not related with Year FullBath is not related with Year HalfBath is not related with Year BedroomAbvGr is not related with Year KitchenAbvGr is not related with Year TotRmsAbvGrd is not related with Year Fireplaces is not related with Year GarageCars is not related with Year GarageArea is not related with Year WoodDeckSF is not related with Year OpenPorchSF is not related with Year EnclosedPorch is not related with Year 3SsnPorch is not related with Year ScreenPorch is not related with Year PoolArea is not related with Year MiscVal is not related with Year MoSold is not related with Year ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold'] 해당 데이터를 히트맵으로 시각화한다. 12345678fig, ax = plt.subplots(3, 1, figsize=(10, 6), sharex=True, sharey=True)for i, var in enumerate(year_feature): if var != 'YrSold': ax[i].scatter(train[var], y, alpha=0.3) ax[i].set_title('{}'.format(var), size=15) ax[i].set_ylabel('SalePrice', size=15, labelpad=12.5)plt.tight_layout()plt.show() ! 해당 데이터에서 리모델링 데이터를 드롭해준다. 12all_df = all_df.drop(['YearBuilt', 'GarageYrBlt'], axis=1)print(all_df.shape) (2917, 71) 12345YearsSinceRemodel = train['YrSold'].astype(int) - train['YearRemodAdd'].astype(int)fig, ax = plt.subplots(figsize=(10, 6))ax.scatter(YearsSinceRemodel, y, alpha=0.3)fig.show() ! 12345all_df['YearsSinceRemodel'] = all_df['YrSold'].astype(int) - all_df['YearRemodAdd'].astype(int)all_df = all_df.drop(['YrSold', 'YearRemodAdd'], axis=1)print(all_df.shape)all_df['YearsSinceRemodel'] = all_df['YrSold'].astype(int) - all_df['YearRemodAdd'].astype(int)all_df = all_df.drop(['YrSold', 'YearRemodAdd'], axis=1)print(all_df.shape) 더미변수1all_df['PoolArea'].value_counts() 0.000000 2904 4.721829 1 5.913421 1 6.161330 1 5.854879 1 5.786591 1 5.553561 1 5.843016 1 6.048366 1 5.130821 1 6.231252 1 5.945809 1 5.922801 1 5.718338 1 Name: PoolArea, dtype: int64 12345def count_dummy(x): if x &gt; 0: return 1 else: return 0 12all_df['PoolArea'] = all_df['PoolArea'].apply(count_dummy)all_df['PoolArea'].value_counts() 0 2904 1 13 Name: PoolArea, dtype: int64 12all_df['GarageArea'] = all_df['GarageArea'].apply(count_dummy)all_df['GarageArea'].value_counts() 1 2760 0 157 Name: GarageArea, dtype: int64 12all_df['Fireplaces'] = all_df['Fireplaces'].apply(count_dummy)all_df['Fireplaces'].value_counts() 1 1497 0 1420 Name: Fireplaces, dtype: int64 문자열 데이터를 변환해준다(Label Encoding, Ordinal Encoding, One-Hot Encoding)12345678910from sklearn.preprocessing import LabelEncoderimport pandas as pdtemp = pd.DataFrame({'Food_Name': ['Apple', 'Chicken', 'Broccoli'], 'Calories': [95, 231, 50]})encoder = LabelEncoder()encoder.fit(temp['Food_Name'])labels = encoder.transform(temp['Food_Name'])print(list(temp['Food_Name']), &quot;==&gt;&quot;, labels) ['Apple', 'Chicken', 'Broccoli'] ==&gt; [0 2 1] 123456789from sklearn.preprocessing import OrdinalEncoderimport pandas as pdtemp = pd.DataFrame({'Food_Name': ['Apple', 'Chicken', 'Broccoli'], 'Calories': [95, 231, 50]})encoder = OrdinalEncoder()labels = encoder.fit_transform(temp[['Food_Name']])print(list(temp['Food_Name']), &quot;==&gt;&quot;, labels.tolist()) ['Apple', 'Chicken', 'Broccoli'] ==&gt; [[0.0], [2.0], [1.0]] 12345678import pandas as pdtemp = pd.DataFrame({'Food_Name': ['Apple', 'Chicken', 'Broccoli'], 'Calories': [95, 231, 50]})temp[['Food_No']] = temp.Food_Name.replace(to_replace = ['Chicken', 'Broccoli', 'Apple'], value = [1, 2, 3])print(temp[['Food_Name', 'Food_No']]) Food_Name Food_No 0 Apple 3 1 Chicken 1 2 Broccoli 2 12345678import pandas as pdtemp = pd.DataFrame({'Food_Name': ['Apple', 'Chicken', 'Broccoli'], 'Calories': [95, 231, 50]})temp = pd.get_dummies(temp)print(temp)print(temp.shape) Calories Food_Name_Apple Food_Name_Broccoli Food_Name_Chicken 0 95 1 0 0 1 231 0 0 1 2 50 0 1 0 (3, 4) 12all_df = pd.get_dummies(all_df).reset_index(drop=True)all_df.shape (2917, 267) 머신러닝 모형 학습 및 평가데이터셋 분리 및 교차 검증123X = all_df.iloc[:len(y), :]X_test = all_df.iloc[len(y):, :]X.shape, y.shape, X_test.shape ((1458, 267), (1458,), (1459, 267)) 123from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)X_train.shape, X_test.shape, y_train.shape, y_test.shape ((1093, 267), (365, 267), (1093,), (365,)) 평가지표 MAE 12345678910import numpy as npdef mean_absolute_error(y_true, y_pred): error = 0 for yt, yp in zip(y_true, y_pred): error = error + np.abs(yt-yp) mae = error / len(y_true) return mae MSE 12345678910import numpy as npdef mean_squared_error(y_true, y_pred): error = 0 for yt, yp in zip(y_true, y_pred): error = error + (yt - yp) ** 2 mse = error / len(y_true) return mse RMSE 1234567891011import numpy as npdef root_rmse_squared_error(y_true, ypred): error = 0 for yt, yp in zip(y_true, y_pred): error = error + (yt - yp) ** 2 mse = error / len(y_true) rmse = np.round(np.sqrt(mse), 3) return rmse TEST1 123456y_true = [400, 300, 800]y_pred = [380, 320, 777]print(&quot;MAE:&quot;, mean_absolute_error(y_true, y_pred))print(&quot;MSE:&quot;, mean_squared_error(y_true, y_pred))print(&quot;RMSE:&quot;, root_rmse_squared_error(y_true, y_pred)) MAE: 21.0 MSE: 443.0 RMSE: 21.048 TEST2 123456y_true = [400, 300, 800, 900]y_pred = [380, 320, 777, 600]print(&quot;MAE:&quot;, mean_absolute_error(y_true, y_pred))print(&quot;MSE:&quot;, mean_squared_error(y_true, y_pred))print(&quot;RMSE:&quot;, root_rmse_squared_error(y_true, y_pred)) MAE: 90.75 MSE: 22832.25 RMSE: 151.103 RMSE with Sklean 1234from sklearn.metrics import mean_squared_errordef rmsle(y_true, y_pred): return np.sqrt(mean_squared_error(y_true, y_pred)) 모형 정의 및 검증 평가 1234567891011121314from sklearn.metrics import mean_squared_errorfrom sklearn.model_selection import KFold, cross_val_scorefrom sklearn.linear_model import LinearRegressiondef cv_rmse(model, n_folds=5): cv = KFold(n_splits=n_folds, random_state=42, shuffle=True) rmse_list = np.sqrt(-cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv)) print('CV RMSE value list:', np.round(rmse_list, 4)) print('CV RMSE mean value:', np.round(np.mean(rmse_list), 4)) return (rmse_list)n_folds = 5rmse_scores = {}lr_model = LinearRegression() 123score = cv_rmse(lr_model, n_folds)print(&quot;linear regression - mean: {:.4f} (std: {:.4f})&quot;.format(score.mean(), score.std()))rmse_scores['linear regression'] = (score.mean(), score.std()) CV RMSE value list: [0.1399 0.1774 0.1514 0.1103 0.1059] CV RMSE mean value: 0.137 linear regression - mean: 0.1370 (std: 0.0266) 첫 번째 최종 예측 값 제출 123456789from sklearn.model_selection import cross_val_predictX = all_df.iloc[:len(y), :]X_test = all_df.iloc[len(y):, :]X.shape, y.shape, X_test.shapelr_model_fit = lr_model.fit(X, y)final_preds = np.floor(np.expm1(lr_model_fit.predict(X_test)))print(final_preds) [118145. 158483. 187263. ... 176406. 116009. 217705.] 1234submission = pd.read_csv(&quot;sample_submission.csv&quot;)submission.iloc[:,1] = final_predsprint(submission.head())submission.to_csv(&quot;The_first_regression.csv&quot;, index=False) Id SalePrice 0 1461 118145.0 1 1462 158483.0 2 1463 187263.0 3 1464 197385.0 4 1465 200573.0","link":"/2021/11/04/Kaggle-house-price/"},{"title":"kaggle pip install 하는법","text":"캐글에서 pip install 하는 법 캐글 notebook 에서 모듈을 인스톨할라고 하면 WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError ('&lt;pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7684da26d0&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/circlify/이라는 오류가 뜨면서 설치가 안된다. -이럴 경우 notebook의 설정을 바꿔주어 해결 할 수 있었다.(웨일, 크롬에서 작동 확인함)위의 이미지 처럼 Settings-internet에서 off가 되어 있다면 on 으로 바꿔줄 경우 정상적으로 인스톨이 가능하다. 필자의 경우 처음 Settings을 들어갔을때 internet 란이 없었다. 그 경우 Settings 하단 인증 부분에 들어가 휴대전화 문자 인증 후, internet 설정이 가능 했다. 출처: https://somjang.tistory.com/entry/Kaggle-Notebook-에서-라이브러리-설치-방법 [솜씨좋은장씨]","link":"/2021/11/07/kaggle_pip_install/"},{"title":"plotly 작성 연습 1","text":"plotly 작성 연습 1- kaggle 에서 데이터셋을 불러와 히스토그램 그래프 작성 pandas, numpy 임포트 및 시각화를 위한 함수 세팅1234567import numpy as np import pandas as pd import plotly.express as px #plotly 시각화 툴 임포트from plotly.subplots import make_subplots # 여러개의 그래프 표현 함수import plotly.figure_factory as ff #특정한 그래프를 그리기 위한 함수import plotly.graph_objs as go 데이터프레임 셋팅 pd.read_csv()함수는 pandas 라이브러리에서 제공하는 함수외부 text파일, csv파일을 불러올 수 있게 해준다. low_memory=False 는 컬럼에 Nan 값이 여러 타입의 데이터가 섞여있을 경우 오류 발생 예방123df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory=False)questions = df.iloc[0, :].Tdf = df.iloc[1:, :] 직군별 남녀 비율을 표현한 히스토그램 작성 1df['Q2'] = df['Q2'].apply(lambda x : 'ETC' if x not in ['Man', 'Woman'] else x) 데이터프레임에 Q2 문항에서 Man, Woman이 아닌 값을 ETC에 반환해주는 코드 1x = df[df['Q2']!='ETC'][['Q5','Q2']] 히스토그램의 X값을 지정해주는 코드 123fig = px.histogram(x, y='Q5', color='Q2', title='Current position: Gender', histnorm='percent', color_discrete_sequence=['#496595','#f36196'], labels=dict(Q2=&quot;Gender&quot;)) fig() 문 px.histogram문을 통해 히스토그램식으로 설정 미리 설정한 x값을 x축에, y축은 Q5의 데이터항목으로 설정 그래프의 제목(title='Current position: Gender) 히스토그램에서 각 항목들이 전체 퍼센트 수치로 표현(histnorm='percent') 막대 색상의 값을 각각 다르게 지정(color_discrete_sequence=['#496595','#f36196']) x축의 값이 된 Q2의 변수 두개를 표현(labels=dict(Q2=&quot;Gender&quot;)))1fig.update_traces(hovertemplate=None, marker=dict(line=dict(width=0))) 히스토그램의 마커에 대한 설정 마커 설정을 위한 함수(fig.update_traces()) 히스토그램 그래프에 마우스를 올릴 경우 나오는 hover 값을 설정해 주지 않음으로 기본적 값만 나오게 한다(hovertemplate=None) 마커의 태두리 두깨를 설정해 준다(marker=dict(line=dict(width=0))))1fig.update_yaxes(showgrid=False, ticksuffix=' ', categoryorder='total ascending') 히스토그램 y축에 대한 설정 y축 설정을 위한 함수(fig.update_yaxes()) 그래프 상 y축 좌표를 보이지 않게 한다(showgrid=False) y축 변수명 옆 추가 설명란, (ticksuffix= ) 코드상 여백이 들어가 있다. y축 정렬을 가장 많은 값 부터 내림차순으로 설정(categoryorder='total ascending')1fig.update_xaxes(visible=False) 히스토그램 x축에 대한 설정 그래프 상 x축 좌표를 보이지 않게 한다.(fig.update_xaxes(visible=False))1234567fig.update_layout(height=1000, bargap=0.2, plot_bgcolor='#fff', paper_bgcolor='#fff', margin=dict(b=0,r=20,l=20), title_font=dict(size=25, color='#333', family=&quot;Lato, sans-serif&quot;), font=dict(color='#8a8d93'), yaxis_title=&quot; &quot;, hovermode='y unified', hoverlabel=dict(bgcolor=&quot;#333&quot;, font_size=13, font_family=&quot;Lato, sans-serif&quot;), legend=dict(orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1, xanchor=&quot;center&quot;, x=0.5)) 그래프 표현에 대한 설정 위에 각 변수에 저장된 그래프들을 한번에 불러와 출력한다.(fig.update_layout) height=1000, = 표 크기 / bargap=0.2, = 바 간격 x축과 y축 사이의 플로팅 영역의 배경색을 설정한다(plot_bgcolor) 그래프 배경색을 설정해준다(paper_bgcolor) 여백주기(margin=dict(b=0,r=20,l=20), ) b=아래, r=오른쪽, l=왼쪽 제목의 폰트 및, 크기 색상 지정(title_font=dict(size=25, color='#fff', family=&quot;Lato, sans-serif&quot;)&lt;/br&gt;,) 그래프의 전반적인 폰트의 색상과 여백, 그리고 hover 타이틀이 될 변수를 설정해준다.(font=dict(color='#8a8d93'), yaxis_title=&quot; &quot;, hovermode='y unified',) hover 의 폰트에 대한 설정 (hoverlabel=dict(bgcolor=&quot;#333&quot;, font_size=13, font_family=&quot;Lato, sans-serif&quot;),) 범례에 대한 설정 (legend=dict(orientation=&quot;h&quot;, yanchor=&quot;bottom&quot;, y=1, xanchor=&quot;right&quot;, x=0.5))) 히스토그램 출력 결과 - 오류와 해결 방안1. 원인 : 모듈을 import할 때 작업 폴더 내 모듈과 동일한 파일이 존재하기 때문입니다. 해결책 : pd.read.csv() 가 아닌 pd.read_csv() 로 변경 후 해결 참고 2. 원인 : Q2의 데이터는 Man, Woman 만 있는 것이 아닌 다른 값들도 존제함.그렇기 때문에 Q2 의 데이터에서 ETC의 값을 제외한 값만을 표현해야 했지만 `ETC가 제대로 설정되어 있지 않았음 해결책 : lamdba 함수에 if ~ else 문을 이용해 Man,Woman일 경우 Q2에 반환되지만, 아닐 경우 ETC 에 반환되도록 함 참고 - 참고한 자료 히스토그램 총 정리 Hover 정리 layout 함수 총 정리","link":"/2021/11/05/plotlyex01/"},{"title":"plotly 작성 연습 2","text":"plotly 작성 연습 2- kaggle 에서 데이터셋을 불러와 Multi-Level Circle 그래프 그리기 데이터프레임 셋팅은 여기 서 확인할 수 있다. 단 circlify 그래프를 그리기 위해 모듈을 설치하는 방법의 경우 아래 코드를 입력1!pip install circlify 1234from pprint import pprintimport circlifyimport matplotlib.pyplot as plt kaggle notebook에서 pip install 하는 것을 알고 싶다면 여기 서 확인 가능 ‘성별별 데이터 사이언티스트에게 입문 프로그래밍 언어 추천 응답에 대한’ 데이터 셋 해당 그래프의 작성법은 여기 를 바탕으로 작성했다. 12df1 = df[df['Q2']!='ETC']df_q2_q8 = pd.crosstab(df1['Q8'], df1['Q2']).reset_index().sort_values(by='Man', ascending=False) reset_index()를 통해 인덱스를 처음으로 재 배열,sort_values(by='Man', ascending=False)를 통해 Man을 기준으로 내림차순 정렬123456789101112131415161718192021222324252627data = [{'id': 'World', 'datum': 50000, 'children' : [ {'id' : &quot;Python&quot;, 'datum' : 30000, 'children' : [ {'id' : &quot;Man&quot;, 'datum' : 16291}, {'id' : &quot;Woman&quot;, 'datum' : 3570}, ]}, {'id' : &quot;R&quot;, 'datum' : 12000, 'children' : [ {'id' : &quot;Man&quot;, 'datum' : 1103}, {'id' : &quot;Woman&quot;, 'datum' : 315}, ]}, {'id' : &quot;SQL&quot;, 'datum' : 8000, 'children' : [ {'id' : &quot;Man&quot;, 'datum' : 984}, {'id' : &quot;Woman&quot;, 'datum' : 321}, ]}, {'id' : &quot;C++&quot;, 'datum' : 3000, 'children' : [ {'id' : &quot;Man&quot;, 'datum' : 347}, {'id' : &quot;Woman&quot;, 'datum' : 85}, ]}, {'id' : &quot;C&quot;, 'datum' : 2000, 'children' : [ {'id' : &quot;Man&quot;, 'datum' : 328}, {'id' : &quot;Woman&quot;, 'datum' : 99}, ]} ]}] 각 원들의 이름(id: World), 크기를 지정해주고(datum: 50000), childeren은 원안에 작은 원이 들어감을 의미1data = [{'id': 'World', 'datum': 50000, 'children' : [ { 각 원의 위치를 계산해준다. data는 가장 큰 값에서 가장 작은 값으로 정렬되어있다.show_enclosure=False는 그래프를 출력 여부를,target_enclosure=circlify.Circle(x=0, y=0, r=1))는 그래프의 위치를 설정해준다.1234circles = circlify.circlify( data, # 필수 show_enclosure=False, #옵션 target_enclosure=circlify.Circle(x=0, y=0, r=1)) #옵션 여러 그래프를 출력하고, 그래프의 제목을 설정해준다. 12fig, ax = plt.subplots(figsize=(14,14))ax.set_title('Top 5 Programming language are recommended to be a Data scientist') 그래프에서 x축과 y축 표현을 안보이게 해준다.1ax.axis('off') 그래프의 각 원들이 서로 점에 마주닿게 설정한다. 12345678910lim = max( max( abs(circle.x) + circle.r, abs(circle.y) + circle.r, ) for circle in circles)plt.xlim(-lim, lim)plt.ylim(-lim, lim) 가장 큰원의 출력값을 설정한다. if circle.level != 2: 은 원의 출력 범위를 조절해준다. x, y, r = circle 은 각각 원을 선언해준다 ax.add_patch( plt.Circle((x, y), r, alpha=0.5, linewidth=2, color=&quot;lightblue&quot;))은 r안에 x,y 원이 들어가며 원들의 태두리와 r의 배경색을 지정해준다.12345for circle in circles: if circle.level != 2: continue x, y, r = circle ax.add_patch( plt.Circle((x, y), r, alpha=0.5, linewidth=2, color=&quot;lightblue&quot;)) 두번째 원의 설정이다. 첫번째 원과 설정은 거의 동일하다. 차이점은 색상과 원 중앙에 흰색 글씨를 넣는 코드가 추가된것이다.plt.annotate(label, (x,y ), ha='center', color=&quot;white&quot;)1234567for circle in circles: if circle.level != 3: continue x, y, r = circle label = circle.ex[&quot;id&quot;] ax.add_patch( plt.Circle((x, y), r, alpha=0.5, linewidth=2, color=&quot;#69b3a2&quot;)) plt.annotate(label, (x,y ), ha='center', color=&quot;white&quot;) 각 원이 뜻하는 범위의 텍스트 박스를 넣어준다. plt.annotate(label, (x,y ) ,va='center', ha='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round', pad=.5)) 123456for circle in circles: if circle.level != 2: continue x, y, r = circle label = circle.ex[&quot;id&quot;] plt.annotate(label, (x,y ) ,va='center', ha='center', bbox=dict(facecolor='white', edgecolor='black', boxstyle='round', pad=.5)) 그래프 출력 결과 참고자료 Circle Packing Chart with Multi-Level Hierarchy Basic Circle Packing Chart","link":"/2021/11/07/plotlyex02/"},{"title":"plotly_math1","text":"리스트 컴프리헨션 함수 리스트 생성하기123numbers = []for n in range(1, 10+1): numbers.append(n) 위의 코드를 컴피리헨션으로 표기하면1[x for x in range(10)] 컴프리헨션은 리스트 내부에 코드를 작성한다. 조건 걸기 1부터 10까지 숫자중 짝수만 순차적으로 들어가 있는 리스트 생성1234even_numbers = []for n in range(1, 10+1): if n % 2 == 0: even_numbers.append(n) 컴프리헨션 for문 작성``````","link":"/2021/11/08/plotly-math/"},{"title":"plotly 작성 연습 3","text":"plotly 작성 연습 3- kaggle 에서 데이터셋을 불러와 top10 국가 그래프 두개 그리기 데이터 정리12# converting : Man, Woman을 제외한 값은 ETCdf['Q2'] = df['Q2'].apply(lambda x : 'ETC' if x not in ['Man', 'Woman'] else x) 필요한 Man,Woman 값을 제외한 나머지는 ETC에 저장 12# replace : 국가명을 하나로 일치df['Q3'] = df['Q3'].replace(['United States of America','United Kingdom of Great Britain and Northern Ireland'], ['USA','UK &amp; NI']) 데이터프레임에 저장된 국가명 중, 같은 나라지만 다른 표기로 된 것을 하나로 통일 시각화 작업 123df = df[df['Q3']!='ETC']df1 = pd.crosstab(df['Q2'], df['Q3'], margins=True).T.sort_values(by='All', ascending=False)[:11].iloc[1: , :].reset_index() crosstab 을 통해 Q2, Q3 를 교차분석 하고, 정렬을 해준다 12345fig = make_subplots(rows=1, cols=2, column_widths=[0.4,0.6], shared_yaxes=True, horizontal_spacing=0)fig.append_trace(go.Bar(x=df_c['Woman'], y=df_c.Q3, orientation='h', showlegend=True, text=df_c['Woman'], name='Woman', marker_color='#6D83AA'), 1, 1)fig.append_trace(go.Bar(x=df_c['Man'], y=df_c.Q3, orientation='h', showlegend=True, text=df_c['Man'], name='Man', marker_color='#334668'), 1, 2) 두개의 그래프의 위치, 들어갈 값, 변수를 정해주고 스타일을 꾸며준다. 12fig.update_xaxes(showgrid=False, zeroline=False)fig.update_yaxes(ticksuffix=' ') 그래프상 좌표를 보이지 않게 한다. 12fig.update_traces(hovertemplate=None, marker=dict(line=dict(width=0)), textposition='auto') 그래프에 마우스를 가져갔을 때 나오는 호버값을 정해준다.따로 정해지지 않았음으로 기본적 정보만 나온다. 12345678fig.update_layout(height=500, barmode='overlay', title=&quot;&lt;span style='font-size:50px; font-family:Times New Roman'&gt;Top 10 Country&lt;/span&gt;&quot;, margin=dict(t=110, b=40, l=120, r=40), plot_bgcolor='#333', paper_bgcolor='#333', title_font=dict(size=30, color='#8a8d93', family=&quot;Lato, sans-serif&quot;), font=dict(size=13, color='#8a8d93'), legend=dict(title=&quot;&quot;, orientation=&quot;v&quot;, yanchor=&quot;bottom&quot;, xanchor=&quot;center&quot;, x=0.83, y=1.05, bordercolor=&quot;#fff&quot;, borderwidth=0.5, font_size=13)) 그래프의 크기, 제목, 여백, 배경색, 글씨체, 등등 스타일을 정해준다 1fig.show() 그래프를 출력한다. 그래프 출력 결과 참고자료참고: https://rfriend.tistory.com/280 [R, Python 분석과 프로그래밍의 친구 (by R Friend)])","link":"/2021/11/09/plotlyex03/"},{"title":"plotly 작성 연습 4","text":"plotly 작성 연습 4- kaggle 에서 데이터셋을 불러와 국가 별 응답수와 특정 국가 % 구하기 데이터 세팅 1country = 'South Korea' country = 를 사용해 본인이 원하는 국가슬 설정한다.이때 원하는 컬럼명과 반드시 일치해야 한다. 12if country not in df[df.columns[3]].unique(): raise ValueError(f'{country} not found in the list') 국가명을 가져오는 과정에서 오류가 뜰 경우 f'{country} not found in the list 가 뜨고 일단 실행되게 한다. 1df['country_agg'] = np.where(df[df.columns[3]]==country,country,'Others') df의 국가명에 조건을 걸어서 배열에 반환한다. 시각화 작업 123fig = px.pie(df, df.columns[3], title=f&quot;{len(df[df[df.columns[3]]==country])*100/len(df):.2f}% of all survey respondents are from {country}&quot;, hole=0.6) 그래프 상에 국가명과 차지하는 %가 몇인지 뜨게 해준다. 123fig.update_traces(textposition='inside', textinfo='percent+label')fig.update_layout(uniformtext_minsize=10, paper_bgcolor='#333',font=dict(size=13, color='#8a8d93'), uniformtext_mode='hide')fig.show() 그래프의 전체적인 스타일을 설정해준다. 그래프 결과 참고자료 유일한 값(unique value) 에러와 예외 pd.where과 np.where의 차이","link":"/2021/11/09/plotlyex04/"},{"title":"통계 Capter01","text":"SPSS 기초1. 변수의 개념 변수(Variable) 란, 연구자가 연구하고자 하는 개념을 뜻한다. ex)성별 나이 학벌 수면 시간 등.. 변수는 위치와 역활에 따라 크게 독립변수, 종속변수, 제3변수로 개념이 나눠진다. 독립변수(Independent Variable)이란 어떤 현상에 원인의 역할을 하는 변수를 의미한다. 종속변수((Dependent Variable)이란 원인에 의해 결과가 달라지는 변수를 의미한다. 2. 척도의 개념 척도(Scale)이란 변수를 측정 가능토록 수치화한 것 을 의미한다. 척도는 크게 명목척도, 등간척도, 서열척도, 비율척도가 있다. 측정 수준 척도 성질 예시 연산 분류 명목척도 (Nominal scale) 고유함 이름, 성별 비가산 집합 서열척도 (ordinal scale) 순서 순위, 서열 비가산 집합 수량 등간척도 (interval scale) 순서, 간격 온도, 지능지수 사칙연산 중 가산가능 비율척도 (Ratio scale) 순서, 간격, 비율 자연수, 몸무게 사칙연산 가능 분석을 진행할 때 독립변수와 종속변수가 각각 어떠한 척도로 구성되어 있는지에 따라 다른 분석법이 사용된다. 그럼으로 분석을 진행하기 전, 변수가 어떠한 척도로 구성되어 있는지 반드시 확인해야만 한다.","link":"/2021/10/31/Statistics_Capter01/"},{"title":"plotly 작성 연습 5","text":"plotly 작성 연습 5- kaggle 에서 데이터셋을 불러와 국가별 응답수를 막대그래프와 지도 형식으로 표현하기12345678import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)import plotly.express as pxdf = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory=False) 12questions = df.iloc[0, :].Tquestions 12df = df.iloc[1:, :].reset_index(drop = True)df.head() 1countries = df.iloc[:, 3] countries에 df의 4번째 열(‘Q3’)을 반환해준다 1country_counts = (countries.value_counts().reset_index()).rename(columns = {'index':'Country','Q3': 'Count'}) country_counts 에 countries의 횟수를 넣어주고 reset_index()) 한 후에 리네임으로 1행 =index 1열=Country , 2행 =Q3, 2열=Count 로 바꿔준다 1country_counts['Country']=country_counts['Country'].replace('Viet Nam', 'Vietnam') country_counts의 Country에 있는 Viet Nam 을 .replace를 통해 Vietnam으로 바꿔주고 반환해준다. 1from urllib.request import urlopen urllib 패키지를 통해 인터넷 소스를 가져 올 수 있게 한다. 1import json 자바스크립트 기반으로 작성환 텍스트 데이터 포맷중 하나. 12with urlopen('https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json') as response: counties = json.load(response) urlopen을 통해 해당 웹페이지의 데이터를 .json 형식으로 받아온다. 1info = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv') info에 지도를 그리기 위한 csv값을 반환해준다. 1di = {} 딕셔너리 생성 12for _,row in info.iterrows(): di[row['COUNTRY']]=row['CODE'] info에 반환받은 각 국가의 CODE 값과 COUNTRY를 새로운 di(딕셔너리)에 넣어준다. 1234567891011121314151617181920212223count=0n=[]c=[]code=[]for key, value in di.items(): for _,row in country_counts.iterrows(): if key in row['Country']: count=count+1 n.append(key) c.append(row['Count']) code.append(value)dfc=pd.DataFrame()dfc['Country']=ndfc['Count']=cdfc['Code']=codedfcn = pd.pivot_table(dfc, index=['Country'],values=['Count'],aggfunc='sum').reset_index()dfc.drop('Count', axis=1, inplace=True)dfcn = pd.merge(left=dfcn, right=dfc, on='Country')dfcn =dfcn.sort_values(by=&quot;Count&quot;)dfcn.drop_duplicates(inplace=True) 데이터 카테고리의 수를 카운트 해준다. 참고 1. 막대그래프 표현12345678fig = px.bar(dfcn, x='Country', y='Count', height=600, color='Count', color_continuous_scale='pinkyl', template='plotly_white')fig.update_xaxes(type='category')fig.update_layout(title={ 'text': &quot;Country wise user count&quot;, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'})fig.show() 데이터셋은 dfcn x축은 국가명, y축은 응답수(카테고리의 수) 단순한 바가 아닌 응답수에 따라 색이 바뀌게(color_contunuous_scale='pinkyl') 2. 지도 표현1234567891011fig = px.choropleth(dfcn, locations='Code', color='Count', color_continuous_scale='pinkyl', hover_name=&quot;Country&quot;, template='plotly_white', hover_data={ 'Code':False })fig.update_layout(title={ 'text': &quot;Demographic distribution of Users&quot;, 'x':0.5, 'xanchor': 'center', 'yanchor': 'top'},dragmode=False)fig.show() 지도 표현을 위한 함수 px.choropleth(plotly.express 패키지 필요) 지도상 정확 위치 표현을 위해 locations=Code를 기준으로 잡아준다. 그 후 각 지역마다 응답수를 색상으로 표현 3. 참고자료 .iterrows 관련 자료1 .iterrows 관련 자료2 DataFrame index reset자료 파이썬으로 json 데이터 읽고 쓰기 피봇 테이블 자료","link":"/2021/11/11/plotlyex05/"},{"title":"plotly 작성 연습 6","text":"plotly 작성 연습 6- kaggle 에서 데이터셋을 불러와 국가별 트리맵 형식으로 표현하기보충 필요123456789101112131415161718192021222324fig = px.treemap(dfcn, path=['Country','Count'], color='Count')fig.update_layout(title=&quot;&lt;b&gt;Countries in the 2021 Survey&lt;b&gt;&quot;, titlefont={'size': 24, 'family': &quot;San Serif&quot;}, height=500, width=700, template='simple_white', paper_bgcolor='#F5F5F5', #plot_bgcolor='#F5F5F5', autosize=False, margin=dict(l=50,r=50,b=50, t=250, ), )fig.update_layout(margin = dict(t=50, l=50, r=50, b=100))annotations = []annotations.append(dict(xref='paper', yref='paper', x=-0.01, y=-0.1, showarrow=False))annotations.append(dict(xref='paper', yref='paper', x=-0.01, y=-0.2, showarrow=False))fig.update_layout(annotations=annotations)fig.show() 시각화 결과","link":"/2021/11/12/plotlyex06/"},{"title":"Python 문법 2","text":"123456789import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename)) 1df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv') 데이터 프레임 접근1df['Q1'] 1df[['Q1','Q2']] 데이터 프레임 객체 생성(인덱스 지정)1# df_1 = pd.DataFrame(df, index=[추가할 인덱스] 데이터 프래임 객체 생성( 컬럼지정) 데이터 중에서 원하는 컬럼만 선택하거나, 순서 변경가능 12df_2 = pd.DataFrame(df, columns=['Q1','Q2','Q3'])df_2 index 심화과정index 정보1df.index index 이름 설정12df.index.name='넘버링'df index 초기화 단, 그냥 drop=True 만 할 경우 다음 df부터는 다시 인덱스가 보여진다. 완전히 지우기 위해서는 inplace=True 를 한다. 1df.reset_index(drop=True) # 내가 설정한 '넘버링' 인덱스가 삭제된다 1df # 위에서 초기화를 했음에도 '넘버링' 이 있는걸 확인 할 수 있다. 1df.reset_index(drop=True, inplace=True) # 실제 데이터에 바로 반영 1df 지정한 컬럼으로 인덱스를 설정 reset_index() 처럼 inplace=True` 를 넣어줘야 반영된다. 1df.set_index('Q3') 인덱스를 기준으로 오름차순, 내림차순 정렬df.sort_index(ascending=False)#ascending=False 없으면 내림차순 1df.describe() 1df['Q2'].describe() 데이터에서 중복된값을 제외한 데이터들을 보여준다.1df['Q3'].unique() 1df.loc[df['Q3'] == 'Japan','Q2'] 12filt = df['Q2'].str.startswith('M')df[filt] 1234langs = ['Japan', 'China']filt = df['Q3'].isin(langs)df[filt].head(20) 데이터 조건걸기데이터 필터걸기데이터 Q3가 Japan 인 데이터들의 Q2 값 1df.loc[df['Q3'] == 'Japan','Q2'] Q2가 M으로 시작하는 데이터들만 출력 12filt = df['Q2'].str.startswith('M')df[filt] 특정한 글자들(Japan, China, South Korea)을 langs로 객체로 만들어주고그 값들이 Q3 안에 들어있을 경우(.isin) 를 출력한다. 123langs = ['Japan', 'China','South Korea']filt = df['Q3'].isin(langs)df[filt] 12filt = df['Q38_B_Part_5'].str.contains('TensorBoard')df[filt] 위처럼 contains로 조건을 걸 경우, 오류가 나는 이유는 컬럼 안에 Na/Nan 데이터가 들어있기 때문이다.이런 오류를 방지하기 위해 코드 뒤에 na=False를 붙여주면 된다. 12filt = df['Q38_B_Part_5'].str.contains('TensorBoard', na=False)df[filt] 1df['Q7_Part_1'].fillna('확인 중') 1df.groupby('Q3') 1df.groupby('Q3').get_group('South Korea','Japan','China') 12df.groupby('Q3').size()['South Korea']# Q3로 그룹화를 하고 난 뒤. size()를 통해 한국만의 크기를 보여준다 1df.groupby('Q3')[['Q1','Q2']]","link":"/2021/11/14/Python02/"},{"title":"pandas 연습3","text":"12345678910import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory = False)df = df[1:].reset_index(drop=True)df_asia = df[df['Q3'].isin(['Japan', 'China', 'South Korea'])]df_usa = df[df['Q3'].isin(['United States of America'])]df_usa.reset_index(drop=True)df_asia.reset_index(drop=True) 1df_usa.reset_index(drop=True) 1df_asia['Q3'].replace(['South Korea', 'Japan', 'China'],['KOR', 'JAP', 'CH'], inplace=True) 1df_usa['Q3'].replace('United States of America', 'USA', inplace=True) 필요없는 대답들 지우기+NULL값 다른 명칭으로 바꾸기 이 데이터는 kaggle 유저들의 답변들이 들어있다. 그래서 답변이 일정하지 않은 것들이 상당하다 예를들어 설명의 값만 보더라도 1df_asia['Q2'].unique() 위에 처럼 Man, Woman 뿐 아니라 응답하지 않음, 나 자신을정의하지 않겠다. 남자여자 둘다 아니다 라는 답변이 있다. 우리에게 필요한 데이터는 남자와 여자 두 응답이라면 이 필요없는 데이터들은 따로 처리해야한다 먼저 떠오르는 것은 Man, Woman을 제외한 나머지 값들을 NaN 즉, null 값으로 만들어 주는 방법이다. 이와 같은 방법으로 우리에게 필요한 설문인 Q1,Q2,Q3,Q4,Q5,Q6,Q7,Q25,Q42 를 편집해보겠다. 1df_asia['Q2'].replace(['Prefer not to say', 'Prefer to self-describe','Nonbinary' ],[np.NaN,np.NaN,np.NaN], inplace=True) 1df_usa['Q2'].replace(['Prefer not to say', 'Prefer to self-describe','Nonbinary' ],[np.NaN,np.NaN,np.NaN], inplace=True) 저번 index 때 학습했던 방법인 replace를 이용해 필요없는 값들을 nan 값으로 바꿔주었다 계속해서 다른 것들도 바꿔줘본다. 이번엔 반대로 null 값인 부분을 다른 값으로 채워보겠다. 예를들어 Q25의 경우 수익을 나타내지만 NaN 값이 상당부분 차지한다. 수익이란 데이터의 특이성을 생각하여 NaN 값이라 할지라도 시각화할 가치가 있기 때문에 다른 데이터를 채워넣어 주겠다. 1df_asia['Q25'].fillna('응답하지않음', inplace = True) 1df_asia['Q25'].head() 위 코드처럼 fillna 를 이용하면 NaN 값을 다른 값으로 변경할 수 있다. 이떄 주의할 것은 위처럼 컬럼을 지정해주지 않으면 데이터 프레임의 모든 NaN값들이 다 바뀌게 된다. 그러니 반드시 특정 컬럼을 지정해주거나 하는 방식을 사용하는 것이 좋을거 같다.","link":"/2021/11/15/kaggle-dataedit/"},{"title":"pandas 연습1","text":"12345678910import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)import osfor dirname, _, filenames in os.walk('/kaggle/input'): for filename in filenames: print(os.path.join(dirname, filename)) 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory = False)df = df[1:].reset_index(drop=True) 데이터 프레임 편집하기기존 데이터 프레임에서 한중일을 따로 빼서 새로운 데이터 프레임 df_asia 로 만들고,미국을 따로 뽑아서 df_usa로 만들기 위해 다양한 필터링 방법을 써보고 그래프까지 뽑아보자 1df.head() 먼저 중복되는 국가명을 제외하고 어떤 국가들이 있는지 먼저 확인해준다. 1df['Q3'].unique() drop을 이용한 방법 12df=df[df.Q3 != 'India']df['Q3'].unique() 위에 결과 처럼 기존 df(데이터프레임) 에서 India를 drop해서 국가에 India가 빠진걸 확인 할 수 있다. 이 방법을 이용해 다른 국가도 한번 빼보자 12345678910111213df=df[df.Q3 != 'Indonesia', 'Pakistan', 'Mexico', 'Russia', 'Turkey', 'Australia', 'Nigeria', 'Greece', 'Belgium', 'Egypt', 'Singapore', 'Brazil', 'Poland', 'Iran, Islamic Republic of...','Italy', 'Viet Nam', 'Israel', 'Peru', 'South Africa', 'Other', 'Spain', 'Bangladesh', 'United Kingdom of Great Britain and Northern Ireland', 'France', 'Switzerland', 'Algeria', 'Tunisia', 'Argentina', 'Sweden', 'Colombia', 'I do not wish to disclose my location', 'Canada', 'Chile', 'Netherlands', 'Ukraine', 'Saudi Arabia', 'Romania', 'Morocco', 'Austria', 'Taiwan', 'Kenya', 'Belarus', 'Ireland', 'Portugal', 'Hong Kong (S.A.R.)', 'Denmark', 'Germany', 'Philippines', 'Sri Lanka', 'United Arab Emirates', 'Uganda', 'Ghana', 'Malaysia', 'Thailand', 'Nepal', 'Kazakhstan', 'Ethiopia', 'Iraq', 'Ecuador', 'Norway', 'Czech Republic'] 많은 국가를 넣으니 키에러가 난다. ㅜㅜ 에러의 원인은 알 수 없지만 국가를 줄여서 한번 더 해본다. 1df=df[df.Q3 != 'Indonesia', 'Pakistan'] 12df=df[df.Q3 != 'Indonesia']df['Q3'].unique() 이유를 알 수는 없지만 1개 이상의 국가를 drop 할때 키에러가 발생하는거 같다. drop 을 이용한 방법은 적은 컬럼에선 가능할 것 같지만, 이 파일처럼 많은 데이터가 있을 경우 매우매우 많은 시간이 걸릴거라 생각된다. 위와같은 이유로 drop을 이용한 방법은 사용하지 못할 것 같다. isin 을 이용한 방법 isin 은 해당 데이터를 True or False로 반환해주는 기능을 한다. 이러한 점을 이용해 국가명을 조건으로 걸어주어서 조건에 맞는 국가만 따로 묶어본다. 12df_asia = df[df['Q3'].isin(['Japan', 'China', 'South Korea'])]df_asia.head() 12df_usa = df[df['Q3'].isin(['United States of America'])]df_usa.head() 성공이다 너무 기분이 좋다ㅎㅎㅎ 하지만 아직 데이터 프레임이 이쁘지 않다. 데이터를 전처리를 해야겠다. 기존 데이터 프레임에서 가져온거라 인덱스 번호가 오락가락이다 새로운 데이터프레임들의 인덱스 번호를 1부터 출력되게 바꿔주자 국가명이 문제다 South Korea 는 정식 명칭이 아니고 United States of America 는 너무 길다 United States of America 를 USA로 바꿔주는 김에 다른 국가들로 다 약어인 CH,JAP,KOR 로 변경해보자 각 질문마다 이상한 애들 (ex. 선택하지 않음, 말하기싫음 등등..)을 다 빼고 내가 원하는 데이터들만 남겨보자 질문들의 이름도 너무 제각각이다. Q38_B_Part_4 이런 애들을 쓰기 쉽게 바꿔보자 각각의 항목은 링크로 걸겠다.","link":"/2021/11/15/kaggle-dataset/"},{"title":"pandas 연습2","text":"12345678910import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory = False)df = df[1:].reset_index(drop=True)df_asia = df[df['Q3'].isin(['Japan', 'China', 'South Korea'])]df_usa = df[df['Q3'].isin(['United States of America'])]df_usa.reset_index(drop=True) 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory = False)df = df[1:].reset_index(drop=True) 1234df_asia = df[df['Q3'].isin(['Japan', 'China', 'South Korea'])]df_usa = df[df['Q3'].isin(['United States of America'])]df_usa.reset_index(drop=True)df_asia.reset_index(drop=True) 1df_asia.reset_index(drop=True) 데이터 프레임에서 데이터명을 바꿔보자 South Korea 는 정식 명칭이 아니고, United States of America 같은 경우 너무 길다. 해당 명칭들을 한눈에 들어오기 좋게 약어로 바꿔보겠다. 1df_asia['Q3'].replace(['South Korea', 'Japan', 'China'],['KOR', 'JAP', 'CH'], inplace=True) 1df_asia.head() 12df_usa['Q3'].replace('United States of America', 'USA', inplace=True)df_usa.head() replace 를 이용해 국가명을 보기 좋게 바꿀 수 있었다. 처음엔 ,inplace=True를 넣지 않았더니 데이터 프레임 원본은 바뀌지 않았다. 까먹지 말자 원본에 반영하기 위해선 , inplace=True 가 필수라는 것을!","link":"/2021/11/15/kaggle-dataname/"},{"title":"pandas 연습4","text":"1234import numpy as np # linear algebraimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) 12df = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv',low_memory = False)df = df[1:].reset_index(drop=True) 12df_asia = df[df['Q3'].isin(['Japan', 'China', 'South Korea'])]df_usa = df[df['Q3'].isin(['United States of America'])] 새로운 데이터 프레임의 index를 새롭게 지정해보자1df_asia.head() 새로운 데이터 프레임의 인덱스 번호가 제각각이다. 이걸 1부터 차례대로 출력되게 바꿔보자 1df_asia.reset_index(list(range(0,2094,1))) 처음 도전한 것은 df_asia.reset_index(list(range(1,2094,1))) 였다. 내가 index를 처음 만들때 처럼 1부터 2094까지 1씩 증가되는 인덱스를 만든다는 의미로 실행했는데 오류가 떴다. 정확한 의미는 모르겠지만 인덱스가 너무 많다는 뜻인거같다. 1df_asia.reset_index(drop=True) 1df_usa.reset_index(drop=True) reset_index는 내 생각보다 더 단순했다. 인덱스를 리셋해주고 기존걸 버리면 자동으로 새로운 인덱스를 추가해줬다. 간단하게 resrt_index(drop=True)를 해주는 것 만으로 기존 인덱스는 사라지고 0부터 끝까지 새로운 인덱스가 추가되었다. 인덱스 추가 클리어 참고자료","link":"/2021/11/15/kaggle-reindex/"}],"tags":[{"name":"Coalb","slug":"Coalb","link":"/tags/Coalb/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"blog","slug":"blog","link":"/tags/blog/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"파이썬","slug":"파이썬","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"Pandas","slug":"Pandas","link":"/tags/Pandas/"},{"name":"Statistics","slug":"Statistics","link":"/tags/Statistics/"},{"name":"SPSS","slug":"SPSS","link":"/tags/SPSS/"},{"name":"numpy","slug":"numpy","link":"/tags/numpy/"},{"name":"colab","slug":"colab","link":"/tags/colab/"},{"name":"visualization","slug":"visualization","link":"/tags/visualization/"},{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"Decision Tree","slug":"Decision-Tree","link":"/tags/Decision-Tree/"},{"name":"kaggle","slug":"kaggle","link":"/tags/kaggle/"},{"name":"plotly","slug":"plotly","link":"/tags/plotly/"},{"name":"시각화","slug":"시각화","link":"/tags/%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"json","slug":"json","link":"/tags/json/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"}],"categories":[{"name":"블로그","slug":"블로그","link":"/categories/%EB%B8%94%EB%A1%9C%EA%B7%B8/"},{"name":"파이썬","slug":"파이썬","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"},{"name":"통계","slug":"통계","link":"/categories/%ED%86%B5%EA%B3%84/"},{"name":"github","slug":"블로그/github","link":"/categories/%EB%B8%94%EB%A1%9C%EA%B7%B8/github/"},{"name":"파이썬 문법","slug":"파이썬/파이썬-문법","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EB%AC%B8%EB%B2%95/"},{"name":"numpy","slug":"파이썬/numpy","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/numpy/"},{"name":"Pandas","slug":"파이썬/Pandas","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/Pandas/"},{"name":"통계 이론","slug":"통계/통계-이론","link":"/categories/%ED%86%B5%EA%B3%84/%ED%86%B5%EA%B3%84-%EC%9D%B4%EB%A1%A0/"},{"name":"데이터 시각화","slug":"파이썬/데이터-시각화","link":"/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%8B%9C%EA%B0%81%ED%99%94/"},{"name":"머신러닝","slug":"머신러닝","link":"/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/"},{"name":"캐글","slug":"캐글","link":"/categories/%EC%BA%90%EA%B8%80/"},{"name":"결정트리 모델","slug":"머신러닝/결정트리-모델","link":"/categories/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%AC-%EB%AA%A8%EB%8D%B8/"},{"name":"캐글 예제","slug":"캐글/캐글-예제","link":"/categories/%EC%BA%90%EA%B8%80/%EC%BA%90%EA%B8%80-%EC%98%88%EC%A0%9C/"},{"name":"캐글 셋팅","slug":"캐글/캐글-셋팅","link":"/categories/%EC%BA%90%EA%B8%80/%EC%BA%90%EA%B8%80-%EC%85%8B%ED%8C%85/"},{"name":"캐글 시험 준비","slug":"캐글/캐글-시험-준비","link":"/categories/%EC%BA%90%EA%B8%80/%EC%BA%90%EA%B8%80-%EC%8B%9C%ED%97%98-%EC%A4%80%EB%B9%84/"}]}